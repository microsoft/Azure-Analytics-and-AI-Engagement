{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47881be6-4520-49ec-96c8-25133772e091",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlflow==2.10.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b29ebe31-4466-4865-9319-7ff302130e81/lib/python3.11/site-packages (2.10.1)\nRequirement already satisfied: langchain in /databricks/python3/lib/python3.11/site-packages (0.1.20)\nRequirement already satisfied: databricks-vectorsearch==0.22 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b29ebe31-4466-4865-9319-7ff302130e81/lib/python3.11/site-packages (0.22)\nRequirement already satisfied: databricks-sdk==0.18.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b29ebe31-4466-4865-9319-7ff302130e81/lib/python3.11/site-packages (0.18.0)\nRequirement already satisfied: click<9,>=7.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow==2.10.1) (8.0.4)\nRequirement already satisfied: cloudpickle<4 in /databricks/python3/lib/python3.11/site-packages (from mlflow==2.10.1) (2.2.1)\nRequirement already satisfied: databricks-cli<1,>=0.8.7 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b29ebe31-4466-4865-9319-7ff302130e81/lib/python3.11/site-packages (from mlflow==2.10.1) (0.18.0)\nRequirement already satisfied: entrypoints<1 in /databricks/python3/lib/python3.11/site-packages (from mlflow==2.10.1) (0.4)\nRequirement already satisfied: gitpython<4,>=2.1.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow==2.10.1) (3.1.27)\nRequirement already satisfied: pyyaml<7,>=5.1 in /databricks/python3/lib/python3.11/site-packages (from mlflow==2.10.1) (6.0)\nRequirement already satisfied: protobuf<5,>=3.12.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow==2.10.1) (4.24.1)\nRequirement already satisfied: pytz<2024 in /databricks/python3/lib/python3.11/site-packages (from mlflow==2.10.1) (2022.7)\nRequirement already satisfied: requests<3,>=2.17.3 in /databricks/python3/lib/python3.11/site-packages (from mlflow==2.10.1) (2.31.0)\nRequirement already satisfied: packaging<24 in /databricks/python3/lib/python3.11/site-packages (from mlflow==2.10.1) (23.2)\nRequirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow==2.10.1) (6.0.0)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow==2.10.1) (0.4.2)\nRequirement already satisfied: alembic!=1.10.0,<2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b29ebe31-4466-4865-9319-7ff302130e81/lib/python3.11/site-packages (from mlflow==2.10.1) (1.16.1)\nRequirement already satisfied: docker<8,>=4.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b29ebe31-4466-4865-9319-7ff302130e81/lib/python3.11/site-packages (from mlflow==2.10.1) (7.1.0)\nRequirement already satisfied: Flask<4 in /databricks/python3/lib/python3.11/site-packages (from mlflow==2.10.1) (2.2.5)\nRequirement already satisfied: numpy<2 in /databricks/python3/lib/python3.11/site-packages (from mlflow==2.10.1) (1.23.5)\nRequirement already satisfied: scipy<2 in /databricks/python3/lib/python3.11/site-packages (from mlflow==2.10.1) (1.11.1)\nRequirement already satisfied: pandas<3 in /databricks/python3/lib/python3.11/site-packages (from mlflow==2.10.1) (1.5.3)\nRequirement already satisfied: querystring-parser<2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b29ebe31-4466-4865-9319-7ff302130e81/lib/python3.11/site-packages (from mlflow==2.10.1) (1.2.4)\nRequirement already satisfied: sqlalchemy<3,>=1.4.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow==2.10.1) (1.4.39)\nRequirement already satisfied: scikit-learn<2 in /databricks/python3/lib/python3.11/site-packages (from mlflow==2.10.1) (1.3.0)\nRequirement already satisfied: pyarrow<16,>=4.0.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow==2.10.1) (14.0.1)\nRequirement already satisfied: markdown<4,>=3.3 in /databricks/python3/lib/python3.11/site-packages (from mlflow==2.10.1) (3.4.1)\nRequirement already satisfied: matplotlib<4 in /databricks/python3/lib/python3.11/site-packages (from mlflow==2.10.1) (3.7.2)\nRequirement already satisfied: gunicorn<22 in /databricks/python3/lib/python3.11/site-packages (from mlflow==2.10.1) (20.1.0)\nRequirement already satisfied: Jinja2<4,>=2.11 in /databricks/python3/lib/python3.11/site-packages (from mlflow==2.10.1) (3.1.2)\nRequirement already satisfied: mlflow-skinny<3,>=2.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b29ebe31-4466-4865-9319-7ff302130e81/lib/python3.11/site-packages (from databricks-vectorsearch==0.22) (2.14.3)\nRequirement already satisfied: google-auth~=2.0 in /databricks/python3/lib/python3.11/site-packages (from databricks-sdk==0.18.0) (2.21.0)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /databricks/python3/lib/python3.11/site-packages (from langchain) (3.8.5)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /databricks/python3/lib/python3.11/site-packages (from langchain) (0.6.7)\nRequirement already satisfied: langchain-community<0.1,>=0.0.38 in /databricks/python3/lib/python3.11/site-packages (from langchain) (0.0.38)\nRequirement already satisfied: langchain-core<0.2.0,>=0.1.52 in /databricks/python3/lib/python3.11/site-packages (from langchain) (0.1.52)\nRequirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /databricks/python3/lib/python3.11/site-packages (from langchain) (0.0.2)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.17 in /databricks/python3/lib/python3.11/site-packages (from langchain) (0.1.63)\nRequirement already satisfied: pydantic<3,>=1 in /databricks/python3/lib/python3.11/site-packages (from langchain) (1.10.6)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /databricks/python3/lib/python3.11/site-packages (from langchain) (8.2.2)\nRequirement already satisfied: azure-storage-file-datalake>12 in /databricks/python3/lib/python3.11/site-packages (from mlflow==2.10.1) (12.14.0)\nRequirement already satisfied: google-cloud-storage>=1.30.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow==2.10.1) (2.10.0)\nRequirement already satisfied: boto3>1 in /databricks/python3/lib/python3.11/site-packages (from mlflow==2.10.1) (1.34.39)\nRequirement already satisfied: botocore>1.34 in /databricks/python3/lib/python3.11/site-packages (from mlflow==2.10.1) (1.34.39)\nRequirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /databricks/python3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\nRequirement already satisfied: multidict<7.0,>=4.5 in /databricks/python3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /databricks/python3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /databricks/python3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\nRequirement already satisfied: frozenlist>=1.1.1 in /databricks/python3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /databricks/python3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\nRequirement already satisfied: Mako in /databricks/python3/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow==2.10.1) (1.2.0)\nRequirement already satisfied: typing-extensions>=4.12 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b29ebe31-4466-4865-9319-7ff302130e81/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow==2.10.1) (4.13.2)\nRequirement already satisfied: azure-core<2.0.0,>=1.28.0 in /databricks/python3/lib/python3.11/site-packages (from azure-storage-file-datalake>12->mlflow==2.10.1) (1.30.2)\nRequirement already satisfied: azure-storage-blob<13.0.0,>=12.19.0 in /databricks/python3/lib/python3.11/site-packages (from azure-storage-file-datalake>12->mlflow==2.10.1) (12.19.1)\nRequirement already satisfied: isodate>=0.6.1 in /databricks/python3/lib/python3.11/site-packages (from azure-storage-file-datalake>12->mlflow==2.10.1) (0.6.1)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /databricks/python3/lib/python3.11/site-packages (from boto3>1->mlflow==2.10.1) (0.10.0)\nRequirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /databricks/python3/lib/python3.11/site-packages (from boto3>1->mlflow==2.10.1) (0.10.2)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /databricks/python3/lib/python3.11/site-packages (from botocore>1.34->mlflow==2.10.1) (2.8.2)\nRequirement already satisfied: urllib3<2.1,>=1.25.4 in /databricks/python3/lib/python3.11/site-packages (from botocore>1.34->mlflow==2.10.1) (1.26.16)\nRequirement already satisfied: pyjwt>=1.7.0 in /usr/lib/python3/dist-packages (from databricks-cli<1,>=0.8.7->mlflow==2.10.1) (2.3.0)\nRequirement already satisfied: oauthlib>=3.1.0 in /usr/lib/python3/dist-packages (from databricks-cli<1,>=0.8.7->mlflow==2.10.1) (3.2.0)\nRequirement already satisfied: tabulate>=0.7.7 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b29ebe31-4466-4865-9319-7ff302130e81/lib/python3.11/site-packages (from databricks-cli<1,>=0.8.7->mlflow==2.10.1) (0.9.0)\nRequirement already satisfied: six>=1.10.0 in /usr/lib/python3/dist-packages (from databricks-cli<1,>=0.8.7->mlflow==2.10.1) (1.16.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /databricks/python3/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.2)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /databricks/python3/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\nRequirement already satisfied: Werkzeug>=2.2.2 in /databricks/python3/lib/python3.11/site-packages (from Flask<4->mlflow==2.10.1) (2.2.3)\nRequirement already satisfied: itsdangerous>=2.0 in /databricks/python3/lib/python3.11/site-packages (from Flask<4->mlflow==2.10.1) (2.0.1)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /databricks/python3/lib/python3.11/site-packages (from gitpython<4,>=2.1.0->mlflow==2.10.1) (4.0.11)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /databricks/python3/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk==0.18.0) (5.4.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /databricks/python3/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk==0.18.0) (0.2.8)\nRequirement already satisfied: rsa<5,>=3.1.4 in /databricks/python3/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk==0.18.0) (4.9)\nRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /databricks/python3/lib/python3.11/site-packages (from google-cloud-storage>=1.30.0->mlflow==2.10.1) (2.18.0)\nRequirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /databricks/python3/lib/python3.11/site-packages (from google-cloud-storage>=1.30.0->mlflow==2.10.1) (2.4.1)\nRequirement already satisfied: google-resumable-media>=2.3.2 in /databricks/python3/lib/python3.11/site-packages (from google-cloud-storage>=1.30.0->mlflow==2.10.1) (2.7.1)\nRequirement already satisfied: setuptools>=3.0 in /databricks/python3/lib/python3.11/site-packages (from gunicorn<22->mlflow==2.10.1) (68.0.0)\nRequirement already satisfied: zipp>=0.5 in /databricks/python3/lib/python3.11/site-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow==2.10.1) (3.11.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.11/site-packages (from Jinja2<4,>=2.11->mlflow==2.10.1) (2.1.1)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /databricks/python3/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.52->langchain) (1.33)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /databricks/python3/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\nRequirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow==2.10.1) (1.0.5)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow==2.10.1) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow==2.10.1) (4.25.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow==2.10.1) (1.4.4)\nRequirement already satisfied: pillow>=6.2.0 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow==2.10.1) (9.4.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow==2.10.1) (3.0.9)\nRequirement already satisfied: opentelemetry-api<3,>=1.9.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny<3,>=2.4.0->databricks-vectorsearch==0.22) (1.25.0)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny<3,>=2.4.0->databricks-vectorsearch==0.22) (1.25.0)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow==2.10.1) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow==2.10.1) (2023.7.22)\nRequirement already satisfied: joblib>=1.1.1 in /databricks/python3/lib/python3.11/site-packages (from scikit-learn<2->mlflow==2.10.1) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.11/site-packages (from scikit-learn<2->mlflow==2.10.1) (2.2.0)\nRequirement already satisfied: greenlet!=0.4.17 in /databricks/python3/lib/python3.11/site-packages (from sqlalchemy<3,>=1.4.0->mlflow==2.10.1) (2.0.1)\nRequirement already satisfied: cryptography>=2.1.4 in /databricks/python3/lib/python3.11/site-packages (from azure-storage-blob<13.0.0,>=12.19.0->azure-storage-file-datalake>12->mlflow==2.10.1) (41.0.3)\nRequirement already satisfied: smmap<6,>=3.0.1 in /databricks/python3/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow==2.10.1) (5.0.0)\nRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /databricks/python3/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage>=1.30.0->mlflow==2.10.1) (1.63.0)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /databricks/python3/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage>=1.30.0->mlflow==2.10.1) (1.24.0)\nRequirement already satisfied: google-crc32c<2.0dev,>=1.0 in /databricks/python3/lib/python3.11/site-packages (from google-resumable-media>=2.3.2->google-cloud-storage>=1.30.0->mlflow==2.10.1) (1.5.0)\nRequirement already satisfied: jsonpointer>=1.9 in /databricks/python3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain) (3.0.0)\nRequirement already satisfied: deprecated>=1.2.6 in /databricks/python3/lib/python3.11/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny<3,>=2.4.0->databricks-vectorsearch==0.22) (1.2.14)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.46b0 in /databricks/python3/lib/python3.11/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny<3,>=2.4.0->databricks-vectorsearch==0.22) (0.46b0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /databricks/python3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk==0.18.0) (0.4.8)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /databricks/python3/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (0.4.3)\nRequirement already satisfied: cffi>=1.12 in /databricks/python3/lib/python3.11/site-packages (from cryptography>=2.1.4->azure-storage-blob<13.0.0,>=12.19.0->azure-storage-file-datalake>12->mlflow==2.10.1) (1.15.1)\nRequirement already satisfied: wrapt<2,>=1.10 in /databricks/python3/lib/python3.11/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny<3,>=2.4.0->databricks-vectorsearch==0.22) (1.14.1)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob<13.0.0,>=12.19.0->azure-storage-file-datalake>12->mlflow==2.10.1) (2.21)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install mlflow==2.10.1 langchain databricks-vectorsearch==0.22 databricks-sdk==0.18.0 mlflow[databricks]\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70377130-3099-4c3f-b41c-2f5335ede016",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./00-init $reset_all_data=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b54422db-6d2f-4179-aa02-b1e84f884f23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "index_name=f\"{catalog}.{db}.vector_search_index\"\n",
    "host = \"https://\" + spark.conf.get(\"spark.databricks.workspaceUrl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "277e09c6-8eb0-48d7-a920-f796209a6118",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# url used to send the request to your model from the serverless endpoint\n",
    "import os\n",
    "host = \"https://\" + spark.conf.get(\"spark.databricks.workspaceUrl\")\n",
    "os.environ['DATABRICKS_TOKEN'] = dbutils.secrets.get('databricksscope', 'databricks-token') \n",
    "#os.environ['DATABRICKS_TOKEN'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e64ebeac-0fc6-45ea-8074-aafefd49326a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test embeddings: [0.0185699462890625, -0.01403045654296875, -0.057647705078125, 0.003448486328125, 0.008575439453125, -0.0216827392578125, -0.0247344970703125, -0.0047149658203125, 0.0136260986328125, 0.050323486328125, -0.027496337890625, -0.0147247314453125, 0.05474853515625, -0.053802490234375, -0.01025390625, -0.0161895751953125, -0.018768310546875, -0.017181396484375, -0.051177978515625, 0.0178680419921875]...\n[NOTICE] Using a Personal Authentication Token (PAT). Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True to VectorSearchClient().\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_community.vectorstores.databricks_vector_search:embedding model is not used in delta-sync index with Databricks-managed embeddings.\n/databricks/python/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n  warn_deprecated(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant documents: page_content='Introduction\\nWoodgrove Financial provides industry-leading benefits to help you and your family get and stay well, prepare for your future, and enjoy life’s journey. Whether you are expecting a new child, looking for some legal advice for a new home, or managing a health condition, Woodgrove Financial is here to support you with benefits and resources to help you live life well.\\nThis Summary Plan Description (SPD) provides details of the health and welfare benefits available to eligible employees and their eligible dependents, as described in this SPD. Other summary plan descriptions address health and welfare benefits that may be offered to other employees and their eligible dependents.\\nAbout the SPD\\nThis document is intended to serve as a Summary Plan Description (SPD) as defined by the Employee Retirement Income Security Act of 1974 (ERISA) for such programs described within that are governed by ERISA. The terms and conditions of the Woodgrove Financial Corporation Welfare Plan (Plan) are set forth in this SPD, in the Woodgrove Financial Corporation Welfare Plan wrap document (the “Welfare Plan”), the Benefits@Woodgrove Financial Program, the Woodgrove Financial Healthcare Reimbursement Plan, the Woodgrove Financial Dental and Vision Care Reimbursement Plan, the Woodgrove Financial Dependent Care Reimbursement Plan, and in the insurance policies and other component plan documents incorporated into the Welfare Plan. The Welfare Plan together with this SPD and the other incorporated documents constitute the written instruments under which the Plan is established and maintained. Where there is an inconsistency or ambiguity between the terms of the Welfare Plan and the terms of a certificate of coverage for insured benefits, the terms of the certificate of coverage control when describing specific benefits that are covered or insurance-related terms. Where there is an inconsistency or ambiguity between the terms of the Welfare Plan and this SPD, the terms of the Welfare Plan control.' metadata={'id': 10.0}\n"
     ]
    }
   ],
   "source": [
    "from databricks.vector_search.client import VectorSearchClient\n",
    "from langchain_community.vectorstores import DatabricksVectorSearch\n",
    "from langchain_community.embeddings import DatabricksEmbeddings\n",
    "\n",
    "# Test embedding Langchain model\n",
    "#NOTE: your question embedding model must match the one used in the chunk in the previous model \n",
    "embedding_model = DatabricksEmbeddings(endpoint=\"databricks-bge-large-en\")\n",
    "print(f\"Test embeddings: {embedding_model.embed_query('What is Apache Spark?')[:20]}...\")\n",
    "\n",
    "def get_retriever(persist_dir: str = None):\n",
    "    os.environ[\"DATABRICKS_HOST\"] = host\n",
    "    #Get the vector search index\n",
    "    vsc = VectorSearchClient(workspace_url=host, personal_access_token=os.environ[\"DATABRICKS_TOKEN\"])\n",
    "    vs_index = vsc.get_index(\n",
    "        endpoint_name=VECTOR_SEARCH_ENDPOINT_NAME,\n",
    "        index_name=index_name\n",
    "    )\n",
    "\n",
    "    # Create the retriever\n",
    "    vectorstore = DatabricksVectorSearch(\n",
    "        vs_index, text_column=\"content\", embedding=embedding_model\n",
    "    )\n",
    "    return vectorstore.as_retriever()\n",
    "\n",
    "# test our retriever\n",
    "vectorstore = get_retriever()\n",
    "similar_documents = vectorstore.get_relevant_documents(\"What policies does Woodgrove Financial have in place to ensure workplace safety?\")\n",
    "print(f\"Relevant documents: {similar_documents[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f1c84bf-5182-4b97-81bc-cc00eb6f754e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n  warn_deprecated(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test chat model: I couldn't find any information on a company called Woodgrove Financial. It's possible that it's a fictional company or a private company that doesn't publicly disclose its policies.\n\nHowever, I can provide general information on common policies that companies may have in place to ensure workplace safety. These can include:\n\n1. Occupational Health and Safety (OHS) policies: Many companies have a written OHS policy that outlines their commitment to providing a safe work environment and the procedures for reporting and investigating incidents.\n2. Hazard identification and risk assessment: Companies may have procedures in place to identify potential hazards in the workplace and assess the risks associated with them.\n3. Training and education: Companies may provide regular training and education to employees on workplace safety procedures, emergency response plans, and the use of personal protective equipment (PPE).\n4. Incident reporting and investigation: Companies may have procedures in place for reporting and investigating incidents, including near misses, injuries, and illnesses.\n5. Emergency response plans: Companies may have emergency response plans in place, including procedures for fires, natural disasters, and other emergencies.\n6. Regular safety inspections: Companies may conduct regular safety inspections to identify potential hazards and ensure compliance with safety regulations.\n7. Employee participation: Companies may encourage employee participation in workplace safety through safety committees, suggestion programs, or other mechanisms.\n\nIf you are looking for specific information on Woodgrove Financial's workplace safety policies, I recommend contacting the company directly or checking their website for more information.\n"
     ]
    }
   ],
   "source": [
    "# Test Databricks Foundation LLM model\n",
    "from langchain_community.chat_models import ChatDatabricks\n",
    "chat_model = ChatDatabricks(endpoint=\"databricks-meta-llama-3-1-405b-instruct\", max_tokens = 2000)  # azure-openai-gpt4-model\n",
    "print(f\"Test chat model: {chat_model.predict('What policies does Woodgrove Financial have in place to ensure workplace safety?')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "59a47751-9630-45f9-89b0-d4dab9928fa0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Building chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "645f63eb-d544-4855-a1c0-207f7a809b69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NOTICE] Using a Personal Authentication Token (PAT). Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True to VectorSearchClient().\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_community.vectorstores.databricks_vector_search:embedding model is not used in delta-sync index with Databricks-managed embeddings.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatDatabricks\n",
    "\n",
    "TEMPLATE = \"\"\"You are an assistant for Woodgrove Financial users. You are answering  If you don't know the answer, just say that you don't know, don't try to make up an answer. Keep the answer as concise as possible.\n",
    "Use the following pieces of context to answer the question at the end:\n",
    "{context}\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=TEMPLATE, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat_model,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=get_retriever(),\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae524237-5377-487f-869d-95a9206888a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n  warn_deprecated(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You may be required to provide evidence of your partnership in connection with a plan audit of dependent eligibility or a claim for benefits. You may also sign the Woodgrove Financial Affidavit of Domestic Partnership before a notary and retain the affidavit in your records.\n\nThe tax treatment differs from covering a spouse because domestic partners generally do not qualify as spouses or dependents for federal income tax purposes. Therefore, the value of company-provided medical, dental, and vision coverage for your domestic partner will be considered imputed income and will be taxable to you.\n"
     ]
    }
   ],
   "source": [
    "# langchain.debug = True #uncomment to see the chain details and the full prompt being sent\n",
    "question = {\"query\": \"What documentation or proof is required when enrolling my domestic partner, and how does the tax treatment differ from covering a spouse?\"}\n",
    "answer = chain.run(question)\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f21fb2ff-f77d-41d4-935c-108329e25496",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Log the model to model registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "def0d53f-bac4-41c8-9b91-cfe1f1dba67b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b29ebe31-4466-4865-9319-7ff302130e81/lib/python3.11/site-packages/mlflow/langchain/utils/__init__.py:670: UserWarning: Using custom serializer to pickle pydantic.fields.ModelField classes, this might miss some fields and validators. To avoid this, please upgrade pydantic to v2 using `pip install pydantic -U` with langchain 0.0.267 and above.\n  warnings.warn(\n2025/05/27 10:40:07 WARNING mlflow.utils.requirements_utils: Detected one or more mismatches between the model's dependencies and the current Python environment:\n - mlflow (current: 2.10.1, required: mlflow==2.14.3)\nTo fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n/databricks/python/lib/python3.11/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ab0acf5dd164aa1a0319200e9f9f8cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'cronos_unity_catalog.cdata.rag_chatbot_model_v02'.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c867ca463c7649308f9856fb622d0a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'cronos_unity_catalog.cdata.rag_chatbot_model_v02'.\n"
     ]
    }
   ],
   "source": [
    "from mlflow.models import infer_signature\n",
    "import mlflow\n",
    "import langchain\n",
    "\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "model_name = f\"{catalog}.{db}.rag_chatbot_model_v01\"\n",
    "\n",
    "with mlflow.start_run(run_name=\"chatbot_rag\") as run:\n",
    "    signature = infer_signature(question, answer)\n",
    "    model_info = mlflow.langchain.log_model(\n",
    "        chain,\n",
    "        loader_fn=get_retriever,  # Load the retriever with DATABRICKS_TOKEN env as secret (for authentication).\n",
    "        artifact_path=\"chain\",\n",
    "        registered_model_name=model_name,\n",
    "        pip_requirements=[\n",
    "            \"mlflow==\" + mlflow.__version__,\n",
    "            \"langchain==\" + langchain.__version__,\n",
    "            \"databricks-vectorsearch\",\n",
    "        ],\n",
    "        input_example=question,\n",
    "        signature=signature\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7fd4aabe-d3c4-48d3-b986-2462b92b4e4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c46fc1fb4974464e90ccd852ae0d46ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b29ebe31-4466-4865-9319-7ff302130e81/lib/python3.11/site-packages/mlflow/langchain/utils/__init__.py:670: UserWarning: Using custom serializer to pickle pydantic.fields.ModelField classes, this might miss some fields and validators. To avoid this, please upgrade pydantic to v2 using `pip install pydantic -U` with langchain 0.0.267 and above.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NOTICE] Using a Personal Authentication Token (PAT). Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True to VectorSearchClient().\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_community.vectorstores.databricks_vector_search:embedding model is not used in delta-sync index with Databricks-managed embeddings.\n/databricks/python/lib/python3.11/site-packages/langchain_community/llms/__init__.py:173: LangChainDeprecationWarning: `` was deprecated in LangChain 0.0.22 and will be removed in 0.3. An updated version of the  exists in the langchain-community package and should be used instead. To use it run `pip install -U langchain-community` and import as `from langchain_community.chat_models import ChatDatabricks`.\n  warn_deprecated(\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'query': 'What documentation or proof is required when enrolling my domestic partner, and how does the tax treatment differ from covering a spouse?',\n",
       " 'result': 'You may be required to provide evidence of your partnership in connection with a plan audit of dependent eligibility or a claim for benefits. You may also sign the Woodgrove Financial Affidavit of Domestic Partnership before a notary and retain the affidavit in your records.\\n\\nThe tax treatment differs from covering a spouse in that domestic partners generally do not qualify as spouses or dependents for federal income tax purposes. Therefore, the value of company-provided medical, dental, and vision coverage for your domestic partner will be considered imputed income and will be taxable to you.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = mlflow.langchain.load_model(model_info.model_uri)\n",
    "model.invoke(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8392ae58-3589-4bc2-b6b1-ebf068c54da9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Deploying our Chat Model as a Serverless Model Endpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aaf5cdf5-6290-4457-9a76-12ccf89cd6aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from databricks.sdk.service.serving import EndpointCoreConfigInput, ServedModelInput, ServedModelInputWorkloadSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "445a16d2-63cc-4479-b503-067eaee1a709",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri('databricks-uc')\n",
    "model_name = f\"{catalog}.{db}.rag_chatbot_model_v01\"\n",
    "serving_endpoint_name = \"rag-chatbot-model-endpoint-v01\"\n",
    "latest_model_version = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54ee57fd-35a0-48d7-9421-6086e5e78a75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create or update serving endpoint\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.serving import EndpointCoreConfigInput, ServedModelInput, ServedModelInputWorkloadSize\n",
    "\n",
    "endpoint_config = EndpointCoreConfigInput(\n",
    "    name=serving_endpoint_name,\n",
    "    served_models=[\n",
    "        ServedModelInput(\n",
    "            model_name=model_name,\n",
    "            model_version=latest_model_version,\n",
    "            workload_size=ServedModelInputWorkloadSize.LARGE,\n",
    "            scale_to_zero_enabled=True,\n",
    "            environment_vars={\n",
    "                \"DATABRICKS_TOKEN\": \"{{secrets/databricksscope/databricks-token}}\" , ## Looks like this token is expired\n",
    "            }\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0601ba13-9c31-48a2-82ec-7caeb0859c0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the endpoint https://adb-835232524225733.13.azuredatabricks.net/ml/endpoints/rag-chatbot-model-endpoint-v3, this will take a few minutes to package and deploy the endpoint...\n"
     ]
    }
   ],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "w = WorkspaceClient()\n",
    "\n",
    "existing_endpoint = next(\n",
    "    (e for e in w.serving_endpoints.list() if e.name == serving_endpoint_name), None\n",
    ")\n",
    "serving_endpoint_url = f\"{host}/ml/endpoints/{serving_endpoint_name}\"\n",
    "if existing_endpoint == None:\n",
    "    print(f\"Creating the endpoint {serving_endpoint_url}, this will take a few minutes to package and deploy the endpoint...\")\n",
    "    w.serving_endpoints.create_and_wait(name=serving_endpoint_name, config=endpoint_config)\n",
    "else:\n",
    "    print(f\"Updating the endpoint {serving_endpoint_url} to version {latest_model_version}, this will take a few minutes to package and deploy the endpoint...\")\n",
    "    w.serving_endpoints.update_config_and_wait(served_models=endpoint_config.served_models, name=serving_endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "3. Register and Deploy RAG model as Endpoint (1)",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}