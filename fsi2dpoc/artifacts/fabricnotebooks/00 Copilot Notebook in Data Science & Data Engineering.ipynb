{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76d3319d-289a-4e72-8863-262ee524d36d",
   "metadata": {
    "jupyter": {
     "magics_cell_name": "magics-cell-markdown",
     "magics_signature": "27ac753c3c60167f65c4d05fa7809cd85f1f0273d5b842aca4f65a01"
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "source": [
    "\n",
    "#### Run the cell below to install the required packages for Copilot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89d4fc8-ccd5-4e08-93ad-d72fb5b06a37",
   "metadata": {
    "jupyter": {
     "magics_cell_name": "magics-cell-code",
     "magics_signature": "f2fd67edf890a73ba04d50cb915084367e32fd4731082321a5d29268",
     "magics_version": "1.0"
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#Run this cell to install the required packages for Copilot\n",
    "%pip install https://aka.ms/chat_magics-0.0.0-py3-none-any.whl\n",
    "%load_ext chat_magics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605081b3-d7af-4119-a1d4-daf35f943d09",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Getting Started with Copilot for Data Engineering & Data Science notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4eb611-0e00-4313-aa02-0da8867eac97",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "##### **Ways to Use Copilot**\n",
    "\n",
    "There are **four ways** to interact with Copilot: \n",
    "\n",
    "- A **Chat Panel** allows you to chat back and forth with Copilot. You can ask for code snippets and answers to questions. This is the same panel that you see throughout the rest of Fabric, meaning that you can also ask questions about your entire workspace. \n",
    "\n",
    "- **Copilot on Notebook Cells** allows you to prompt Copilot from the top of each of your notebook cells to generate code in code cells or Markdown in Markdown cell. \n",
    "\n",
    "- **iPython “magics” commands** allows you to ask Copilot questions or for code using simple magic commands in notebook cells. %%code will generate code in a cell much like Copilot on Notebook Cells, but %%chat in code cells allows you to ask questions and get a text response in the cell output \n",
    "\n",
    "- **Quick Actions** that simplify tedious tasks using AI, such as fixing code errors and adding code comments "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee520a4d-1965-42a1-bd37-00673c243e9a",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "##### Feature 1: Chat Panel \n",
    "\n",
    "**Question:** Please load the \"operatingexpenses\" table from the \"#LAKEHOUSE_SILVER#\" Lakehouse Explorer into a Spark DataFrame. Then convert that into pandas dataframe as df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3276e08c-484e-4a5f-8167-d1d59e5c4850",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "%%code\n",
    "\n",
    "Please load the \"operatingexpenses\" table from the \"#LAKEHOUSE_SILVER#\" Lakehouse Explorer into a Spark DataFrame. Then convert that into pandas dataframe as df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ed344a-a936-47b7-ad38-a5c20efc3e49",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "##### Feature 2: Copilot on Notebook Cells "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc8c0c1-de45-437b-8efc-0022e101847e",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "######  2.1 : Data Wrangler\n",
    "\n",
    "**Question:** Create a Data Wrangling function for df with the non-null values in the NetSales, dropping LineItem and converting NetSales, Budget into float and Forecast to float values. Then apply the function into df to create wrangled dataframe df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27103b1-6641-46d3-a295-0e714d31826a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# ATTENTION: AI-generated code can include errors or operations you didn't intend. Review the code in this cell carefully before running it.\n",
    "\n",
    "def data_wrangling(df):\n",
    "    # Filter out rows where NetSales is not null\n",
    "    df = df[df['NetSales'].notnull()]\n",
    "\n",
    "    # Drop the 'LineItem' column\n",
    "    df = df.drop(columns=['LineItem'])\n",
    "\n",
    "    # Convert 'NetSales', 'Budget', and 'Forecast' columns to float\n",
    "    df['NetSales'] = df['NetSales'].astype(float)\n",
    "    df['Budget'] = df['Budget'].astype(float)\n",
    "    df['Forecast'] = df['Forecast'].astype(float)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply the data wrangling function to create the wrangled dataframe\n",
    "df_wrangled = data_wrangling(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a7cc1f-af70-4a62-9d4e-13a34623eb45",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "###### 2.2 : Exploratory Data Analysis\n",
    "\n",
    "**Question:** Create a pivot table of average with min and max NetSales by ProductCategory and Region. Then show the output of pivot table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aafb32f-5b32-4227-868f-0e0639c7a6d8",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# ATTENTION: AI-generated code can include errors or operations you didn't intend. Review the code in this cell carefully before running it.\n",
    "\n",
    "# Create a pivot table of average, min, and max NetSales by ProductCategory and Region\n",
    "pivot_table = df_wrangled.pivot_table(values='NetSales', index=['ProductCategory', 'Region'], aggfunc={'NetSales': ['mean', 'min', 'max']})\n",
    "\n",
    "# Show the output of the pivot table\n",
    "pivot_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1650d72b-f04d-4a61-80de-fa4ff51bc7aa",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "##### Feature 3: iPython “magics” commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0b49a8-4ff8-4ac1-95da-9a8b74fd15a0",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%%chat\n",
    "Create a Seaborn scatter plot with Budget, Forecast, and ProductCategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a11d91b-d323-4811-995b-87a210c8dc63",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# ATTENTION: AI-generated code can include errors or operations you didn't intend. Review the code in this cell carefully before running it.\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.scatterplot(data=df, x='Budget', y='Forecast', hue='Product Category')\n",
    "plt.title('Budget vs Forecast by Product Category')\n",
    "plt.xlabel('Budget')\n",
    "plt.ylabel('Forecast')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33721887-a8e4-45ac-ac36-04d343102af3",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "##### Feature 4: Quick Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f1eeee-23bf-4e1f-801f-9d2d06609a8c",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# ATTENTION: AI-generated code can include errors or operations you didn't intend. Review the code in this cell carefully before running it.\n",
    "\n",
    "# Load the \"operatingexpenses\" table from the FSI_Lakehouse_Silver Lakehouse Explorer into a Spark DataFrame\n",
    "df_spark = spark.read.table(\"#LAKEHOUSE_SILVER#.operatingexpenses\")\n",
    "\n",
    "# Convert the Spark DataFrame into a Pandas DataFrame\n",
    "df = df_spark.toandas()"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "lakehouse": {
    "default_lakehouse": "e57eb953-986e-4c7e-b04d-821ddd3aba7b",
    "default_lakehouse_name": "FSI_Lakehouse_Silver",
    "default_lakehouse_workspace_id": "2b3be873-2fa8-4bd2-b0e6-4b91ac5083a1"
   }
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  },
  "widgets": {}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
