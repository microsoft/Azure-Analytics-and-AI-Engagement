{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "\n",
    "# Predictive Maintenance (PdM) in Manufacturing \n",
    "<h3><span style=\"color: #117d30;\"> Using Automated ML </span></h3>  \n",
    "\n",
    "\n",
    "\n",
    "![](https://dreamdemostorageforgen2.blob.core.windows.net/mfgdemodata/PdM_Demo.jpg)\n",
    "\n",
    "\n",
    "## Overview\n",
    "*Dataset*: Telemetry data from 1000 machines **(8.6 Million events)** with reference data for machine failures, errors, past routine maintenance, and general information about machines. Time series features were extracted from telemetry data.\n",
    "\n",
    "*Tools/Techniques*: AutoML \n",
    "\n",
    "### Notebook Organization \n",
    "+ Ingest featured manufacturing dataset\n",
    "\n",
    "+ Create or use existing cluster\n",
    "\n",
    "+ Prepare the model for deployment \n",
    "\n",
    "+ Submit the experiment to Azure ML to track the logs and metrics \n",
    "\n",
    "+ Build the AutoML model \n",
    "\n",
    "+ Deploy the best AutoML model as a Web Service \n",
    "\n",
    "+ Test the REST API and do inferencing \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.train.automl import AutoMLConfig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure workspace using credentials for Azure subscription\n",
    "\n",
    "As part of the setup you have already created a Workspace. To run AutoML, you also need to create an Experiment. An Experiment corresponds to a prediction problem you are trying to solve, while a Run corresponds to a specific approach to the problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "# Importing user defined config\n",
    "import config\n",
    "\n",
    "# Import the subscription details as below to access the resources\n",
    "subscription_id=config.subscription_id\n",
    "resource_group=config.resource_group\n",
    "workspace_name=config.workspace_name\n",
    "\n",
    "ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\n",
    "ws.write_config()\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute \n",
    "\n",
    "You will need to create a compute target for your AutoML run. In this tutorial, you create AmlCompute as your training compute resource.\n",
    "\n",
    "Creation of AmlCompute takes approximately 5 minutes.\n",
    "If the AmlCompute with that name is already in your workspace this code will skip the creation process. As with other Azure services, there are limits on certain resources (e.g. AmlCompute) associated with the Azure Machine Learning service. Please read this article on the default limits and how to request more quota.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Choose a name for your CPU cluster\n",
    "cpu_cluster_name = \"mfgg-cluster\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',\n",
    "                                                           max_nodes=4)\n",
    "    compute_target = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "\n",
    "compute_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Registered datasets \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(731358, 40)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "train_data = Dataset.get_by_name(ws,\"pdmmfg\")\n",
    "\n",
    "pdtrain_data = train_data.to_pandas_dataframe()\n",
    "\n",
    "pdtrain_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data for model building\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volt_rollingmean_12</th>\n",
       "      <th>rotate_rollingmean_12</th>\n",
       "      <th>pressure_rollingmean_12</th>\n",
       "      <th>vibration_rollingmean_12</th>\n",
       "      <th>volt_rollingmean_24</th>\n",
       "      <th>rotate_rollingmean_24</th>\n",
       "      <th>pressure_rollingmean_24</th>\n",
       "      <th>vibration_rollingmean_24</th>\n",
       "      <th>volt_rollingmean_36</th>\n",
       "      <th>vibration_rollingmean_36</th>\n",
       "      <th>...</th>\n",
       "      <th>error2sum_rollingmean_24</th>\n",
       "      <th>error3sum_rollingmean_24</th>\n",
       "      <th>error4sum_rollingmean_24</th>\n",
       "      <th>error5sum_rollingmean_24</th>\n",
       "      <th>comp1sum</th>\n",
       "      <th>comp2sum</th>\n",
       "      <th>comp3sum</th>\n",
       "      <th>comp4sum</th>\n",
       "      <th>age</th>\n",
       "      <th>label_e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>166.950543</td>\n",
       "      <td>294.433319</td>\n",
       "      <td>94.473184</td>\n",
       "      <td>49.062098</td>\n",
       "      <td>165.197336</td>\n",
       "      <td>278.987299</td>\n",
       "      <td>97.318305</td>\n",
       "      <td>50.799015</td>\n",
       "      <td>166.522216</td>\n",
       "      <td>47.969229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>489.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>564.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>165.290113</td>\n",
       "      <td>285.328277</td>\n",
       "      <td>96.147439</td>\n",
       "      <td>51.315016</td>\n",
       "      <td>164.807180</td>\n",
       "      <td>272.786127</td>\n",
       "      <td>99.193202</td>\n",
       "      <td>49.970419</td>\n",
       "      <td>167.168538</td>\n",
       "      <td>46.472198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>489.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>564.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>164.324247</td>\n",
       "      <td>260.243976</td>\n",
       "      <td>102.238964</td>\n",
       "      <td>48.625823</td>\n",
       "      <td>168.107750</td>\n",
       "      <td>313.399517</td>\n",
       "      <td>102.155735</td>\n",
       "      <td>44.050788</td>\n",
       "      <td>170.913102</td>\n",
       "      <td>42.977346</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>488.0</td>\n",
       "      <td>548.0</td>\n",
       "      <td>548.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>171.891253</td>\n",
       "      <td>366.555058</td>\n",
       "      <td>102.072506</td>\n",
       "      <td>39.475754</td>\n",
       "      <td>174.207530</td>\n",
       "      <td>370.407544</td>\n",
       "      <td>101.847041</td>\n",
       "      <td>40.153107</td>\n",
       "      <td>171.536284</td>\n",
       "      <td>40.345945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>488.0</td>\n",
       "      <td>548.0</td>\n",
       "      <td>548.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>176.523807</td>\n",
       "      <td>374.260029</td>\n",
       "      <td>101.621576</td>\n",
       "      <td>40.830461</td>\n",
       "      <td>171.358800</td>\n",
       "      <td>384.893390</td>\n",
       "      <td>98.324312</td>\n",
       "      <td>40.781041</td>\n",
       "      <td>168.852995</td>\n",
       "      <td>40.246936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>487.0</td>\n",
       "      <td>547.0</td>\n",
       "      <td>547.0</td>\n",
       "      <td>562.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   volt_rollingmean_12  rotate_rollingmean_12  pressure_rollingmean_12  \\\n",
       "0           166.950543             294.433319                94.473184   \n",
       "1           165.290113             285.328277                96.147439   \n",
       "2           164.324247             260.243976               102.238964   \n",
       "3           171.891253             366.555058               102.072506   \n",
       "4           176.523807             374.260029               101.621576   \n",
       "\n",
       "   vibration_rollingmean_12  volt_rollingmean_24  rotate_rollingmean_24  \\\n",
       "0                 49.062098           165.197336             278.987299   \n",
       "1                 51.315016           164.807180             272.786127   \n",
       "2                 48.625823           168.107750             313.399517   \n",
       "3                 39.475754           174.207530             370.407544   \n",
       "4                 40.830461           171.358800             384.893390   \n",
       "\n",
       "   pressure_rollingmean_24  vibration_rollingmean_24  volt_rollingmean_36  \\\n",
       "0                97.318305                 50.799015           166.522216   \n",
       "1                99.193202                 49.970419           167.168538   \n",
       "2               102.155735                 44.050788           170.913102   \n",
       "3               101.847041                 40.153107           171.536284   \n",
       "4                98.324312                 40.781041           168.852995   \n",
       "\n",
       "   vibration_rollingmean_36   ...     error2sum_rollingmean_24  \\\n",
       "0                 47.969229   ...                          0.0   \n",
       "1                 46.472198   ...                          0.0   \n",
       "2                 42.977346   ...                          0.0   \n",
       "3                 40.345945   ...                          0.0   \n",
       "4                 40.246936   ...                          0.0   \n",
       "\n",
       "   error3sum_rollingmean_24  error4sum_rollingmean_24  \\\n",
       "0                       0.0                       0.0   \n",
       "1                       0.0                       0.0   \n",
       "2                       0.0                       0.0   \n",
       "3                       0.0                       0.0   \n",
       "4                       0.0                       0.0   \n",
       "\n",
       "   error5sum_rollingmean_24  comp1sum  comp2sum  comp3sum  comp4sum  age  \\\n",
       "0                       0.0     489.0     549.0     549.0     564.0   18   \n",
       "1                       0.0     489.0     549.0     549.0     564.0   18   \n",
       "2                       0.0     488.0     548.0     548.0     563.0   18   \n",
       "3                       0.0     488.0     548.0     548.0     563.0   18   \n",
       "4                       0.0     487.0     547.0     547.0     562.0   18   \n",
       "\n",
       "   label_e  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_columns = ['machineID','dt_truncated', 'failure','model_encoded','model']\n",
    "\n",
    "pdtrain_data.drop(remove_columns, axis=1, inplace=True)\n",
    "\n",
    "pdtrain_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing the top 5 records in the y_train dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading ../data/x_train.csv\n",
      "Uploaded ../data/x_train.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from azureml.core.dataset import Dataset\n",
    "from scipy import sparse\n",
    "import os \n",
    " \n",
    "# Create a project_folder if it doesn't exist\n",
    "if not os.path.isdir('data'):\n",
    " os.mkdir('data')\n",
    " \n",
    "if not os.path.exists('project_folder'):\n",
    " os.makedirs('project_folder')\n",
    " \n",
    "pdtrain_data.to_csv('./data/x_train.csv')\n",
    "ds = ws.get_default_datastore()\n",
    "ds.upload(src_dir='./data', target_path='synapsemfgdata', overwrite=True, show_progress=True)\n",
    " \n",
    "mfg_train = Dataset.Tabular.from_delimited_files(path=ds.path('synapsemfgdata/x_train.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model - Please do not run the below step as it will take two hours to complete the model building.\n",
    "## Set AutoML Configuration Parameters\n",
    "\n",
    "The AutoMLConfig object defines the settings and data for an AutoML training job. Here, we set necessary inputs like the grain column name, the number of AutoML iterations to try, the training data, and cross-validation parameters.\n",
    "\n",
    "It is generally recommended that users set forecast horizons to less than 100 time periods\n",
    "\n",
    "Furthermore, AutoML's memory use and computation time increases in proportion to the length of the horizon, so consider carefully how this value is set. If a long horizon forecast really is necessary, consider aggregating the series to a coarser time scale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "label_column_name = 'label_e' \n",
    "\n",
    "automl_config = AutoMLConfig(task='classification',\n",
    "                             debug_log='automl_debuglog.log',\n",
    "                             verbosity = logging.INFO,  \n",
    "                             primary_metric='AUC_weighted',\n",
    "                             iteration_timeout_minutes = 15,\n",
    "                             experiment_timeout_hours=1, \n",
    "                             enable_early_stopping=True,\n",
    "                             #featurization='auto', \n",
    "                             max_concurrent_iterations=2,\n",
    "                             max_cores_per_iteration=-1,\n",
    "                             enable_dnn=False,                             \n",
    "                             n_cross_validations=2,                                                      \n",
    "                             compute_target=compute_target, #amlcompute_target (to execute on aml cluster) \n",
    "                             #spark_context=sc, \n",
    "                             training_data=mfg_train,  \n",
    "                             label_column_name='label_e',\n",
    "                             #target_column_name='label_e',\n",
    "                             enable_stack_ensemble=False,\n",
    "                             enable_voting_ensemble=False,\n",
    "                             momfgdel_explainability=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up \n",
    "\n",
    "As part of the setup you have already created a Workspace. To run AutoML, you also need to create an Experiment. An Experiment corresponds to a prediction problem you are trying to solve, while a Run corresponds to a specific approach to the problem.\n",
    "\n",
    "## Experiment \n",
    "Call the submit method on the experiment object and pass the run configuration. Execution of local runs is synchronous. Depending on the data and the number of iterations this can run for a while. In this example, we specify show_output = True to print currently running iterations to the console. utomated ML runs more than 25 Machine Learning Algorithms and grades them according to performance.\n",
    "\n",
    "## Please be aware that the below step will take around 2 hours to complete.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment(Name: mfg_final_exp,\n",
      "Workspace: Auto-ML-2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Received unrecognized parameter momfgdel_explainability\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on remote or ADB.\n",
      "Running on remote compute: mfgg-cluster\n",
      "Parent Run ID: AutoML_de749252-6671-4c01-94da-a35dea2da072\n",
      "\n",
      "Current status: FeaturesGeneration. Generating features for the dataset.\n",
      "Current status: DatasetBalancing. Performing class balancing sweeping\n",
      "Current status: DatasetCrossValidationSplit. Generating individually featurized CV splits.\n",
      "Current status: ModelSelection. Beginning model selection.\n",
      "\n",
      "****************************************************************************************************\n",
      "DATA GUARDRAILS: \n",
      "\n",
      "TYPE:         Class balancing detection\n",
      "STATUS:       DONE\n",
      "DESCRIPTION:  A problem of class imbalance in your dataset has been detected and fixed.\n",
      "              Learn more about imbalanced data: https://aka.ms/AutomatedMLImbalancedData\n",
      "DETAILS:      Imbalanced data can lead to a falsely perceived positive effect of a model's accuracy because the input data has bias towards one class.\n",
      "+---------------------------------+---------------------------------+--------------------------------------+\n",
      "|Size of the smallest class       |Name/Label of the smallest class |Number of samples in the training data|\n",
      "+=================================+=================================+======================================+\n",
      "|7922                             |3.0                              |731358                                |\n",
      "+---------------------------------+---------------------------------+--------------------------------------+\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "TYPE:         Missing feature values imputation\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  No feature missing values were detected in the training data.\n",
      "              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "TYPE:         High cardinality feature detection\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  Your inputs were analyzed, and no high cardinality features were detected.\n",
      "              Learn more about high cardinality feature handling: https://aka.ms/AutomatedMLFeaturization\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "****************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "****************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Received unrecognized parameter momfgdel_explainability\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0   MaxAbsScaler LightGBM                          0:04:05       0.8352    0.8352\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.experiment import Experiment\n",
    "experiment = Experiment(ws, \"mfg_final_exp\")\n",
    "print(experiment)\n",
    "local_run = experiment.submit(automl_config, show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the best model \n",
    "Each run within an Experiment stores serialized (i.e. pickled) pipelines from the AutoML iterations. We can now retrieve the pipeline with the best performance on the validation dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Received unrecognized parameter momfgdel_explainability\n",
      "WARNING - Received unrecognized parameter momfgdel_explainability\n",
      "WARNING - The version of the SDK does not match the version the model was trained on.\n",
      "WARNING - The consistency in the result may not be guaranteed.\n",
      "WARNING - Package:azureml-automl-core, training version:1.10.0.post1, current version:1.9.0\n",
      "Package:azureml-automl-runtime, training version:1.10.0.post1, current version:1.9.0\n",
      "Package:azureml-core, training version:1.10.0, current version:1.9.0\n",
      "Package:azureml-dataset-runtime, training version:1.10.0, current version:1.9.0\n",
      "Package:azureml-defaults, training version:1.10.0, current version:1.9.0\n",
      "Package:azureml-explain-model, training version:1.10.0, current version:1.9.0\n",
      "Package:azureml-interpret, training version:1.10.0, current version:1.9.0\n",
      "Package:azureml-pipeline-core, training version:1.10.0, current version:1.9.0\n",
      "Package:azureml-telemetry, training version:1.10.0, current version:1.9.0\n",
      "Package:azureml-train-automl-client, training version:1.10.0, current version:1.9.0\n",
      "Package:azureml-train-automl-runtime, training version:1.10.0, current version:1.9.0\n",
      "WARNING - Please ensure the version of your local conda dependencies match the version on which your model was trained in order to properly retrieve your model.\n"
     ]
    }
   ],
   "source": [
    "best_run, fitted_model = local_run.get_output() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the best run model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: mfg_final_exp,\n",
      "Id: AutoML_de749252-6671-4c01-94da-a35dea2da072_0,\n",
      "Type: azureml.scriptrun,\n",
      "Status: Completed)\n"
     ]
    }
   ],
   "source": [
    "print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('datatransformer', DataTransformer(enable_dnn=None, enable_feature_sweeping=None,\n",
      "        feature_sweeping_config=None, feature_sweeping_timeout=None,\n",
      "        featurization_config=None, force_text_dnn=None,\n",
      "        is_cross_validation=None, is_onnx_compatible=None, logger=None,\n",
      "        obser...    silent=True, subsample=1.0, subsample_for_bin=200000,\n",
      "          subsample_freq=0, verbose=-10))])\n",
      "Y_transformer(['LabelEncoder', LabelEncoder()])\n"
     ]
    }
   ],
   "source": [
    "print(fitted_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registering the model in Azure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Received unrecognized parameter momfgdel_explainability\n",
      "WARNING - Received unrecognized parameter momfgdel_explainability\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AutoMLde74925260'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#register model\n",
    "description = \"Mfg Classification Model\"\n",
    "model = local_run.register_model(description = description, tags={'Synapse': 'MFGModel'})\n",
    "local_run.model_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create scoring script\n",
    "Create the scoring script, called score.py, used by the web service call to show how to use the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving scoring and conda file\n",
    "script_file_name = 'inference/score.py'\n",
    "conda_env_file_name = 'inference/env.yml'\n",
    "#/content/azureml_automl.log\n",
    "best_run.download_file('outputs/scoring_file_v_1_0_0.py', 'inference/score.py')\n",
    "best_run.download_file('outputs/conda_env_v_1_0_0.yml', 'inference/env.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify package dependency for the environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "conda = CondaDependencies.create(conda_packages=['numpy>=1.16.0,<=1.16.2','pandas','scikit-learn','py-xgboost<=0.80','fbprophet==0.5','psutil>=5.2.2,<6.0.0'],pip_packages=['azureml-defaults==1.0.83','azureml-train-automl-runtime==1.0.83.1','inference-schema','azureml-explain-model==1.0.83'])\n",
    "\n",
    "myenv=Environment(name=\"automlenv\")\n",
    "myenv.python.conda_dependencies = conda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operationalize Model\n",
    "Operationalization means getting the model into the cloud so that other can run it after you close the notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model as a Web Service on Azure Kubernetes Service \n",
    "##### (We have limited recources, hence please DO NOT RUN the below cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running........\n",
      "Succeeded\n",
      "AKS service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AksWebservice\n",
    "from azureml.core.compute import AksCompute\n",
    "from azureml.core.model import Model\n",
    "\n",
    "aks_name = 'new-aks'\n",
    "aks_target = AksCompute(workspace=ws,name=aks_name)\n",
    "\n",
    "aks_config = AksWebservice.deploy_configuration(cpu_cores=1,memory_gb=1,auth_enabled=True)\n",
    "\n",
    "inference_config = InferenceConfig(environment=myenv,\n",
    "                                     entry_script = script_file_name)\n",
    "\n",
    "api_service_name = 'mfg-realtime-pdm'\n",
    "\n",
    "api_service = Model.deploy(workspace=ws,\n",
    "                           name=api_service_name, \n",
    "                           models=[model],\n",
    "                           inference_config=inference_config, \n",
    "                           deployment_config=aks_config,\n",
    "                           deployment_target=aks_target,\n",
    "                           overwrite=True)\n",
    "\n",
    "api_service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print logs for the API service\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-08-07T00:21:53,797365257+00:00 - iot-server/run \\n2020-08-07T00:21:53,798512659+00:00 - rsyslog/run \\n2020-08-07T00:21:53,798864659+00:00 - gunicorn/run \\n2020-08-07T00:21:53,800213962+00:00 - nginx/run \\n/usr/sbin/nginx: /azureml-envs/azureml_30c59c771a2c9019c4ce2fec8745f381/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_30c59c771a2c9019c4ce2fec8745f381/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_30c59c771a2c9019c4ce2fec8745f381/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_30c59c771a2c9019c4ce2fec8745f381/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_30c59c771a2c9019c4ce2fec8745f381/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\nrsyslogd: /azureml-envs/azureml_30c59c771a2c9019c4ce2fec8745f381/lib/libuuid.so.1: no version information available (required by rsyslogd)\\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\\n2020-08-07T00:21:53,874333601+00:00 - iot-server/finish 1 0\\n2020-08-07T00:21:53,875666703+00:00 - Exit code 1 is normal. Not restarting iot-server.\\nStarting gunicorn 19.9.0\\nListening at: http://127.0.0.1:31311 (13)\\nUsing worker: sync\\nworker timeout is set to 300\\nBooting worker with pid: 42\\nInitialized PySpark session.\\nInitializing logger\\nStarting up app insights client\\nStarting up request id generator\\nStarting up app insight hooks\\nInvoking user\\'s init function\\nFailure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception module \\'azureml\\' has no attribute \\'dataprep\\'.\\nUsers\\'s init has completed successfully\\nSkipping middleware: dbg_model_info as it\\'s not enabled.\\nScoring timeout setting is not found. Use default timeout: 3600000 ms\\n200\\n127.0.0.1 - - [07/Aug/2020:00:22:06 +0000] \"GET /swagger.json HTTP/1.0\" 200 5362 \"-\" \"-\"\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_service.get_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the state of the deployed Web Service\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "print(api_service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferencing using the REST API Endpoint\n",
    "![](https://dreamdemostorageforgen2.blob.core.windows.net/mfgdemodata/PdM_Demo.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'{\"result\": [4.0]}'\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import os\n",
    "import ssl\n",
    "import pprint\n",
    "def allowSelfSignedHttps(allowed):\n",
    "    # bypass the server certificate verification on client side\n",
    "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
    "        ssl._create_default_https_context = ssl._create_unverified_context\n",
    "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n",
    "data = {\"data\":\n",
    "        [\n",
    "            [   \n",
    "               406666,18,471.0,561.0, 471.0,501.0,0.0,0.0,0.0,0.0,0.0, 100.8627300454,99.521999589, 100.5907092691,1.3880873096,0.4344249378,0.3170432616, 467.5608723852,454.581998628,\n",
    "               453.1206566629,4.3627672673,2.3310135872,2.2852285336,39.5870951038,39.1100578052,39.3093083177,0.50726284, 0.2221514412,0.1285150643,173.4308768104,171.2252424426, 169.9352949247,1.1288641558, \n",
    "               0.8682283269,0.8146674578\n",
    "            ]\n",
    "        ]               \n",
    "}\n",
    "body = str.encode(json.dumps(data))\n",
    "url = api_service.scoring_uri \n",
    "print(url) # Replace the URL with your Endpoint URL\n",
    "api_key = api_service.get_keys()[0] # Replace this with the API key for the web service\n",
    "print(api_key)\n",
    "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\n",
    "req = urllib.request.Request(url, body, headers)\n",
    "try:\n",
    "    response = urllib.request.urlopen(req)\n",
    "\n",
    "    result = response.read()\n",
    "    #print(result)\n",
    "    pprint.pprint(json.loads(result))\n",
    "except urllib.error.HTTPError as error:\n",
    "    print(\"The request failed with status code: \" + str(error.code))\n",
    "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
    "    print(error.info())\n",
    "    print(json.loads(error.read().decode(\"utf8\", 'ignore')))"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "sessionKeepAliveTimeout": 30
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
