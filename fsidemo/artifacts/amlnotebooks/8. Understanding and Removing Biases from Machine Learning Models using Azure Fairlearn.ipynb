{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Unfairness Mitigation with Fairlearn and Azure Machine Learning\n",
        "**This notebook shows how to upload results from Fairlearn's GridSearch mitigation algorithm into a dashboard in Azure Machine Learning Studio**\n",
        "## Disclaimer\n",
        "\n",
        "By accessing this code, you acknowledge the code is made available for presentation and demonstration purposes only and that the code (1) is not subject to SOC 1 and SOC 2 compliance audits, and (2) is not designed or intended to be a substitute for the professional advice, diagnosis, treatment, or judgment of a certified financial services professional. Do not use this code to replace, substitute, or provide professional financial advice, or judgement. You are solely responsible for ensuring the regulatory, legal, and/or contractual compliance of any use of the code, including obtaining any authorizations or consents, and any solution you choose to build that incorporates this code in whole or in part.\n",
        "\n",
        "Â© 2021 Microsoft Corporation. All rights reserved\n",
        "## Table of Contents\n",
        "\n",
        "1. Introduction\n",
        "1. Loading the Data\n",
        "1. Training an Unmitigated Model)\n",
        "1. Mitigation with GridSearch\n",
        "1. Uploading a Fairness Dashboard to Azure\n",
        "    1. Registering models\n",
        "    1. Computing Fairness Metrics\n",
        "    1. Uploading to Azure\n",
        "1. Conclusion\n",
        "\n",
        "<a id=\"Introduction\"></a>\n",
        "## Introduction\n",
        "This notebook shows how to use Fairlearn (an open-source fairness assessment and unfairness mitigation package) and Azure Machine Learning Studio for a binary classification problem. In this notebook, we will be using a loan decision dataset. The label indicates whether or not each individual repaid a loan in the past. We will use the data to train a predictor to predict whether previously unseen individuals will repay a loan or not. The assumption is that the model predictions are used to decide whether an individual should be offered a loan.\n",
        "\n",
        " \n",
        "\n",
        "Farilearn mitigates disparity using two types of algorithms, reduction, and post-processing. We will apply the grid search algorithm, a reduction algorithm, from the Fairlearn package using a specific notion of fairness called Demographic Parity. Reduction algorithms reduce disparity by training models on reweighted datasets. This produces a set of models, and we will view these in a dashboard both locally and in the Azure Machine Learning Studio. We will also see the trade-off between model performance and disparity visually through Fairlearn dashboards, which can help make an informed decision about the model.\n",
        "\n",
        "### Setup\n",
        "\n",
        "To use this notebook, an Azure Machine Learning workspace is required. This notebook also requires the following packages:\n",
        "* `azureml-contrib-fairness`\n",
        "* `fairlearn==0.4.6` (v0.5.0 will work with minor modifications)\n",
        "* `joblib`\n",
        "* `liac-arff`\n",
        "\n",
        "Fairlearn relies on features introduced in v0.22.1 of `scikit-learn`. If you have an older version already installed, please uncomment and run the following cell:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install -U sklearn\r\n",
        "import sklearn\r\n",
        "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The scikit-learn version is 0.24.2.\n"
          ]
        }
      ],
      "execution_count": 14,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1627301737122
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, please ensure that when you downloaded this notebook, you also downloaded the `fairness_nb_utils.py` file from the same location, and placed it in the same directory as this notebook."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"LoadingData\"></a>\n",
        "## Loading the Data\n",
        "We use the well-known `adult` loan dataset, which we will fetch from the OpenML website. We start with a fairly unremarkable set of imports:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from fairlearn.reductions import GridSearch, DemographicParity, ErrorRate\n",
        "from fairlearn.widget import FairlearnDashboard\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import make_column_selector as selector\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "import pandas as pd"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1627301023900
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now load and inspect the data:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "data = fetch_openml(data_id=1590, as_frame=True)\n",
        "# Extract the items we want\n",
        "X_raw = data.data\n",
        "y = (data.target == '>50K') * 1\n",
        "\n",
        "print(X_raw[\"race\"].value_counts())\n",
        "X_raw"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "White                 41762\n",
            "Black                  4685\n",
            "Asian-Pac-Islander     1519\n",
            "Amer-Indian-Eskimo      470\n",
            "Other                   406\n",
            "Name: race, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "        age     workclass    fnlwgt     education  education-num  \\\n0      25.0       Private  226802.0          11th            7.0   \n1      38.0       Private   89814.0       HS-grad            9.0   \n2      28.0     Local-gov  336951.0    Assoc-acdm           12.0   \n3      44.0       Private  160323.0  Some-college           10.0   \n4      18.0           NaN  103497.0  Some-college           10.0   \n...     ...           ...       ...           ...            ...   \n48837  27.0       Private  257302.0    Assoc-acdm           12.0   \n48838  40.0       Private  154374.0       HS-grad            9.0   \n48839  58.0       Private  151910.0       HS-grad            9.0   \n48840  22.0       Private  201490.0       HS-grad            9.0   \n48841  52.0  Self-emp-inc  287927.0       HS-grad            9.0   \n\n           marital-status         occupation relationship   race     sex  \\\n0           Never-married  Machine-op-inspct    Own-child  Black    Male   \n1      Married-civ-spouse    Farming-fishing      Husband  White    Male   \n2      Married-civ-spouse    Protective-serv      Husband  White    Male   \n3      Married-civ-spouse  Machine-op-inspct      Husband  Black    Male   \n4           Never-married                NaN    Own-child  White  Female   \n...                   ...                ...          ...    ...     ...   \n48837  Married-civ-spouse       Tech-support         Wife  White  Female   \n48838  Married-civ-spouse  Machine-op-inspct      Husband  White    Male   \n48839             Widowed       Adm-clerical    Unmarried  White  Female   \n48840       Never-married       Adm-clerical    Own-child  White    Male   \n48841  Married-civ-spouse    Exec-managerial         Wife  White  Female   \n\n       capital-gain  capital-loss  hours-per-week native-country  \n0               0.0           0.0            40.0  United-States  \n1               0.0           0.0            50.0  United-States  \n2               0.0           0.0            40.0  United-States  \n3            7688.0           0.0            40.0  United-States  \n4               0.0           0.0            30.0  United-States  \n...             ...           ...             ...            ...  \n48837           0.0           0.0            38.0  United-States  \n48838           0.0           0.0            40.0  United-States  \n48839           0.0           0.0            40.0  United-States  \n48840           0.0           0.0            20.0  United-States  \n48841       15024.0           0.0            40.0  United-States  \n\n[48842 rows x 14 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>fnlwgt</th>\n      <th>education</th>\n      <th>education-num</th>\n      <th>marital-status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours-per-week</th>\n      <th>native-country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>25.0</td>\n      <td>Private</td>\n      <td>226802.0</td>\n      <td>11th</td>\n      <td>7.0</td>\n      <td>Never-married</td>\n      <td>Machine-op-inspct</td>\n      <td>Own-child</td>\n      <td>Black</td>\n      <td>Male</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40.0</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>38.0</td>\n      <td>Private</td>\n      <td>89814.0</td>\n      <td>HS-grad</td>\n      <td>9.0</td>\n      <td>Married-civ-spouse</td>\n      <td>Farming-fishing</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>50.0</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>28.0</td>\n      <td>Local-gov</td>\n      <td>336951.0</td>\n      <td>Assoc-acdm</td>\n      <td>12.0</td>\n      <td>Married-civ-spouse</td>\n      <td>Protective-serv</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40.0</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>44.0</td>\n      <td>Private</td>\n      <td>160323.0</td>\n      <td>Some-college</td>\n      <td>10.0</td>\n      <td>Married-civ-spouse</td>\n      <td>Machine-op-inspct</td>\n      <td>Husband</td>\n      <td>Black</td>\n      <td>Male</td>\n      <td>7688.0</td>\n      <td>0.0</td>\n      <td>40.0</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>18.0</td>\n      <td>NaN</td>\n      <td>103497.0</td>\n      <td>Some-college</td>\n      <td>10.0</td>\n      <td>Never-married</td>\n      <td>NaN</td>\n      <td>Own-child</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>30.0</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>48837</th>\n      <td>27.0</td>\n      <td>Private</td>\n      <td>257302.0</td>\n      <td>Assoc-acdm</td>\n      <td>12.0</td>\n      <td>Married-civ-spouse</td>\n      <td>Tech-support</td>\n      <td>Wife</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>38.0</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>48838</th>\n      <td>40.0</td>\n      <td>Private</td>\n      <td>154374.0</td>\n      <td>HS-grad</td>\n      <td>9.0</td>\n      <td>Married-civ-spouse</td>\n      <td>Machine-op-inspct</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40.0</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>48839</th>\n      <td>58.0</td>\n      <td>Private</td>\n      <td>151910.0</td>\n      <td>HS-grad</td>\n      <td>9.0</td>\n      <td>Widowed</td>\n      <td>Adm-clerical</td>\n      <td>Unmarried</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40.0</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>48840</th>\n      <td>22.0</td>\n      <td>Private</td>\n      <td>201490.0</td>\n      <td>HS-grad</td>\n      <td>9.0</td>\n      <td>Never-married</td>\n      <td>Adm-clerical</td>\n      <td>Own-child</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>20.0</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>48841</th>\n      <td>52.0</td>\n      <td>Self-emp-inc</td>\n      <td>287927.0</td>\n      <td>HS-grad</td>\n      <td>9.0</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Wife</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>15024.0</td>\n      <td>0.0</td>\n      <td>40.0</td>\n      <td>United-States</td>\n    </tr>\n  </tbody>\n</table>\n<p>48842 rows Ã 14 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1624542746095
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfupdate=X_raw.sample(5000)  #Number of sample you want to update\r\n",
        "\r\n",
        "dfupdate.race=\"Black\" #Assigning new category\r\n",
        "\r\n",
        "X_raw.update(dfupdate)\r\n",
        "#update_list = dfupdate.index.tolist()\r\n",
        "print(X_raw[\"race\"].value_counts())\r\n",
        "\r\n",
        "for col in ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country' ]:\r\n",
        "    X_raw[col] = X_raw[col].astype('category')\r\n",
        "X_raw.dtypes\r\n",
        "print(X_raw)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "White                 37491\n",
            "Black                  9202\n",
            "Asian-Pac-Islander     1373\n",
            "Amer-Indian-Eskimo      410\n",
            "Other                   366\n",
            "Name: race, dtype: int64\n",
            "        age     workclass    fnlwgt     education  education-num  \\\n",
            "0      25.0       Private  226802.0          11th            7.0   \n",
            "1      38.0       Private   89814.0       HS-grad            9.0   \n",
            "2      28.0     Local-gov  336951.0    Assoc-acdm           12.0   \n",
            "3      44.0       Private  160323.0  Some-college           10.0   \n",
            "4      18.0           NaN  103497.0  Some-college           10.0   \n",
            "...     ...           ...       ...           ...            ...   \n",
            "48837  27.0       Private  257302.0    Assoc-acdm           12.0   \n",
            "48838  40.0       Private  154374.0       HS-grad            9.0   \n",
            "48839  58.0       Private  151910.0       HS-grad            9.0   \n",
            "48840  22.0       Private  201490.0       HS-grad            9.0   \n",
            "48841  52.0  Self-emp-inc  287927.0       HS-grad            9.0   \n",
            "\n",
            "           marital-status         occupation relationship   race     sex  \\\n",
            "0           Never-married  Machine-op-inspct    Own-child  Black    Male   \n",
            "1      Married-civ-spouse    Farming-fishing      Husband  White    Male   \n",
            "2      Married-civ-spouse    Protective-serv      Husband  Black    Male   \n",
            "3      Married-civ-spouse  Machine-op-inspct      Husband  Black    Male   \n",
            "4           Never-married                NaN    Own-child  White  Female   \n",
            "...                   ...                ...          ...    ...     ...   \n",
            "48837  Married-civ-spouse       Tech-support         Wife  Black  Female   \n",
            "48838  Married-civ-spouse  Machine-op-inspct      Husband  Black    Male   \n",
            "48839             Widowed       Adm-clerical    Unmarried  White  Female   \n",
            "48840       Never-married       Adm-clerical    Own-child  White    Male   \n",
            "48841  Married-civ-spouse    Exec-managerial         Wife  White  Female   \n",
            "\n",
            "       capital-gain  capital-loss  hours-per-week native-country  \n",
            "0               0.0           0.0            40.0  United-States  \n",
            "1               0.0           0.0            50.0  United-States  \n",
            "2               0.0           0.0            40.0  United-States  \n",
            "3            7688.0           0.0            40.0  United-States  \n",
            "4               0.0           0.0            30.0  United-States  \n",
            "...             ...           ...             ...            ...  \n",
            "48837           0.0           0.0            38.0  United-States  \n",
            "48838           0.0           0.0            40.0  United-States  \n",
            "48839           0.0           0.0            40.0  United-States  \n",
            "48840           0.0           0.0            20.0  United-States  \n",
            "48841       15024.0           0.0            40.0  United-States  \n",
            "\n",
            "[48842 rows x 14 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/pandas/core/frame.py:5819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[col] = expressions.where(mask, this, that)\n",
            "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        }
      ],
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1624542748278
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to treat the sex and race of each individual as protected attributes, and in this particular case we are going to remove these attributes from the main data. Protected attributes are often denoted by 'A' in the literature, and we follow that convention here:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "A = X_raw[['sex','race']]\n",
        "X_raw = X_raw.drop(labels=['sex', 'race'], axis = 1)"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1624542756279
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now preprocess our data. To avoid the problem of data leakage, we split our data into training and test sets before performing any other transformations. Subsequent transformations (such as scalings) will be fit to the training data set, and then applied to the test dataset."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, X_test, y_train, y_test, A_train, A_test) = train_test_split(\n",
        "    X_raw, y, A, test_size=0.3, random_state=12345, stratify=y)\n",
        "\n",
        "# Ensure indices are aligned between X, y and A,\n",
        "# after all the slicing and splitting of DataFrames\n",
        "# and Series\n",
        "\n",
        "X_train = X_train.reset_index(drop=True)\n",
        "X_test = X_test.reset_index(drop=True)\n",
        "y_train = y_train.reset_index(drop=True)\n",
        "y_test = y_test.reset_index(drop=True)\n",
        "A_train = A_train.reset_index(drop=True)\n",
        "A_test = A_test.reset_index(drop=True)"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1624542758767
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have two types of column in the dataset - categorical columns which will need to be one-hot encoded, and numeric ones which will need to be rescaled. We also need to take care of missing values. We use a simple approach here, but please bear in mind that this is another way that bias could be introduced (especially if one subgroup tends to have more missing values).\n",
        "\n",
        "For this preprocessing, we make use of `Pipeline` objects from `sklearn`:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_transformer = Pipeline(\n",
        "    steps=[\n",
        "        (\"impute\", SimpleImputer()),\n",
        "        (\"scaler\", StandardScaler()),\n",
        "    ]\n",
        ")\n",
        "\n",
        "categorical_transformer = Pipeline(\n",
        "    [\n",
        "        (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, selector(dtype_exclude=\"category\")),\n",
        "        (\"cat\", categorical_transformer, selector(dtype_include=\"category\")),\n",
        "    ]\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1624542761452
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, the preprocessing pipeline is defined, we can run it on our training data, and apply the generated transform to our test data:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = preprocessor.fit_transform(X_train)\n",
        "X_test = preprocessor.transform(X_test)"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1624542764494
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"UnmitigatedModel\"></a>\n",
        "## Training an Unmitigated Model\n",
        "\n",
        "So we have a point of comparison, we first train a model (specifically, logistic regression from scikit-learn) on the raw data, without applying any mitigation algorithm:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "unmitigated_predictor = LogisticRegression(solver='liblinear', fit_intercept=True)\n",
        "\n",
        "unmitigated_predictor.fit(X_train, y_train)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "LogisticRegression(solver='liblinear')"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1624542767814
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can view this model in the fairness dashboard, and see the disparities which appear:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "FairlearnDashboard(sensitive_features=A_test[[\"race\"]], sensitive_feature_names=['Race'],\n",
        "                   y_true=y_test,\n",
        "                   y_pred={\"unmitigated\": unmitigated_predictor.predict(X_test)})"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/fairlearn/widget/_fairlearn_dashboard.py:47: UserWarning: The FairlearnDashboard will move from Fairlearn to the raiwidgets package after the v0.5.0 release. Instead, Fairlearn will provide some of the existing functionality through matplotlib-based visualizations.\n",
            "  warn(\"The FairlearnDashboard will move from Fairlearn to the \"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "FairlearnWidget(value={'true_y': [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1â¦",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0db9bf9af1d4ea49b5ef3c55450d14a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "<fairlearn.widget._fairlearn_dashboard.FairlearnDashboard at 0x7f8fbb99ce10>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1624542773048
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"AzureUpload\"></a>\r\n",
        "## Uploading a Fairness Dashboard to Azure (one time job)\r\n",
        "\r\n",
        "Uploading a fairness dashboard to Azure is a two stage process. The `FairlearnDashboard` invoked in the previous section relies on the underlying Python kernel to compute metrics on demand. This is obviously not available when the fairness dashboard is rendered in AzureML Studio. By default, the dashboard in Azure Machine Learning Studio also requires the models to be registered. The required stages are therefore:\r\n",
        "1. Register the dominant models\r\n",
        "1. Precompute all the required metrics\r\n",
        "1. Upload to Azure\r\n",
        "\r\n",
        "Before that, we need to connect to Azure Machine Learning Studio:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Experiment, Model\r\n",
        "import joblib\r\n",
        "import os\r\n",
        "\r\n",
        "ws = Workspace.from_config()\r\n",
        "ws.get_details()\r\n",
        "\r\n",
        "os.makedirs('models', exist_ok=True)\r\n",
        "\r\n",
        "# Function to register models into Azure Machine Learning\r\n",
        "def register_model(name, model):\r\n",
        "    print(\"Registering \", name)\r\n",
        "    model_path = \"models/{0}.pkl\".format(name)\r\n",
        "    joblib.dump(value=model, filename=model_path)\r\n",
        "    registered_model = Model.register(model_path=model_path,\r\n",
        "                                    model_name=name,\r\n",
        "                                    workspace=ws)\r\n",
        "    print(\"Registered \", registered_model.id)\r\n",
        "    return registered_model.id\r\n",
        "\r\n",
        "# Call the register_model function \r\n",
        "lr_reg_id = register_model(\"unfairness_model_for_race_v2\", unmitigated_predictor)\r\n",
        "#  Create a dictionary of model(s) you want to assess for fairness \r\n",
        "sf = { 'Race': A_test.race}\r\n",
        "ys_pred = { lr_reg_id:unmitigated_predictor.predict(X_test) }\r\n",
        "from fairlearn.metrics._group_metric_set import _create_group_metric_set\r\n",
        "\r\n",
        "dash_dict = _create_group_metric_set(y_true=y_test,\r\n",
        "                                    predictions=ys_pred,\r\n",
        "                                    sensitive_features=sf,\r\n",
        "                                    prediction_type='binary_classification')\r\n",
        "\r\n",
        "from azureml.contrib.fairness import upload_dashboard_dictionary, download_dashboard_by_upload_id\r\n",
        "\r\n",
        "exp = Experiment(ws, \"Unfairness_Experiment_for_Race_v2\")\r\n",
        "print(exp)\r\n",
        "\r\n",
        "run = exp.start_logging()\r\n",
        "\r\n",
        "# Upload the dashboard to Azure Machine Learning\r\n",
        "try:\r\n",
        "    dashboard_title = \"Fairness insights of Regression Classifier for Race\"\r\n",
        "    # Set validate_model_ids parameter of upload_dashboard_dictionary to False if you have not registered your model(s)\r\n",
        "    upload_id = upload_dashboard_dictionary(run,\r\n",
        "                                            dash_dict,\r\n",
        "                                            dashboard_name=dashboard_title)\r\n",
        "    print(\"\\nUploaded to id: {0}\\n\".format(upload_id))\r\n",
        "\r\n",
        "    # To test the dashboard, you can download it back and ensure it contains the right information\r\n",
        "    downloaded_dict = download_dashboard_by_upload_id(run, upload_id)\r\n",
        "finally:\r\n",
        "    run.complete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Registering  unfairness_model_for_race_v2\n",
            "Registering model unfairness_model_for_race_v2\n",
            "Registered  unfairness_model_for_race_v2:1\n",
            "Experiment(Name: Unfairness_Experiment_for_Race_v2,\n",
            "Workspace: ml-fsi-prod)\n",
            "\n",
            "Uploaded to id: ff0987ec-e341-4e76-98f6-935021871bba\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_dashboard_validation.py:Starting validation of dashboard dictionary\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_dashboard_validation.py:Validation of dashboard dictionary successful\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_azureml_validation.py:Validating model ids exist\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_azureml_validation.py:Checking unfairness_model_for_race_v2:1\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_azureml_validation.py:Validation of model ids complete\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Uploading y_true\n",
            "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/ff0987ec-e341-4e76-98f6-935021871bba/y_true/f7972940-4883-4395-b6d8-6fa9f7dedfe4.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded y_true to prefix azureml.fairness/dashboard.metrics/ff0987ec-e341-4e76-98f6-935021871bba/y_true/f7972940-4883-4395-b6d8-6fa9f7dedfe4.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Found 1 predictions\n",
            "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/ff0987ec-e341-4e76-98f6-935021871bba/y_pred/14277707-8df7-49c8-826b-581e10ef2ad7.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded prediction to prefix azureml.fairness/dashboard.metrics/ff0987ec-e341-4e76-98f6-935021871bba/y_pred/14277707-8df7-49c8-826b-581e10ef2ad7.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded 1 predictions\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Found {0} sensitive features\n",
            "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/ff0987ec-e341-4e76-98f6-935021871bba/sensitive_features_column/8816bf2e-f668-4b6e-bbf6-9de002613b9c.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded sensitive feature column to prefix azureml.fairness/dashboard.metrics/ff0987ec-e341-4e76-98f6-935021871bba/sensitive_features_column/8816bf2e-f668-4b6e-bbf6-9de002613b9c.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded 1 sensitive features\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Uploading metrics\n",
            "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/ff0987ec-e341-4e76-98f6-935021871bba/metrics_set/4060d2da-e62a-4160-abe0-8edf9b9efe31.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded metrics data for prediction 0 and sensitive_feature 0\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Creating CUF Assets\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Asset uploaded with id aa1fb43531374090a0793efc7e9bd3b4\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Fetching asset list\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Populating y_true\n",
            "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/ff0987ec-e341-4e76-98f6-935021871bba/y_true/f7972940-4883-4395-b6d8-6fa9f7dedfe4.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Populating y_pred\n",
            "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/ff0987ec-e341-4e76-98f6-935021871bba/y_pred/14277707-8df7-49c8-826b-581e10ef2ad7.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Populating sensitive features\n",
            "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/ff0987ec-e341-4e76-98f6-935021871bba/sensitive_features_column/8816bf2e-f668-4b6e-bbf6-9de002613b9c.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Populating metrics\n",
            "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/ff0987ec-e341-4e76-98f6-935021871bba/metrics_set/4060d2da-e62a-4160-abe0-8edf9b9efe31.json\n"
          ]
        }
      ],
      "execution_count": 49,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1624557327929
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"Mitigation\"></a>\n",
        "## Mitigation with GridSearch\n",
        "\n",
        "The `GridSearch` class in `Fairlearn` implements a simplified version of the exponentiated gradient reduction. The user supplies a standard ML estimator, which is treated as a blackbox - for this simple example, we shall use the logistic regression estimator from scikit-learn. `GridSearch` works by generating a sequence of relabellings and reweightings, and trains a predictor for each.\n",
        "\n",
        "For this example, we specify demographic parity (on the protected attribute of race) as the fairness metric. Demographic parity requires that individuals are offered the opportunity (a loan in this example) independent of membership in the protected class (i.e., females and males should be offered loans at the same rate). *We are using this metric for the sake of simplicity* in this example; the appropriate fairness metric can only be selected after *careful examination of the broader context* in which the model is to be used.\n",
        "    "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "sweep = GridSearch(LogisticRegression(solver='liblinear', fit_intercept=True),\n",
        "                   constraints=DemographicParity(),\n",
        "                   grid_size=71)"
      ],
      "outputs": [],
      "execution_count": 50,
      "metadata": {
        "gather": {
          "logged": 1624559684612
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With our estimator created, we can fit it to the data. After `fit()` completes, we extract the full set of predictors from the `GridSearch` object.\n",
        "\n",
        "The following cell trains a many copies of the underlying estimator, and may take a minute or two to run:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "sweep.fit(X_train, y_train,\n",
        "          sensitive_features=A_train.sex)\n",
        "\n",
        "# For Fairlearn v0.5.0, need sweep.predictors_\n",
        "predictors = sweep.predictors_"
      ],
      "outputs": [],
      "execution_count": 51,
      "metadata": {
        "gather": {
          "logged": 1624559871130
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We could load these predictors into the Fairness dashboard now. However, the plot would be somewhat confusing due to their number. In this case, we are going to remove the predictors which are dominated in the error-disparity space by others from the sweep (note that the disparity will only be calculated for the protected attribute; other potentially protected attributes will *not* be mitigated). In general, one might not want to do this, since there may be other considerations beyond the strict optimisation of error and disparity (of the given protected attribute)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "errors, disparities = [], []\n",
        "for m in predictors:\n",
        "    classifier = lambda X: m.predict(X)\n",
        "    \n",
        "    error = ErrorRate()\n",
        "    error.load_data(X_train, pd.Series(y_train), sensitive_features=A_train.sex)\n",
        "    disparity = DemographicParity()\n",
        "    disparity.load_data(X_train, pd.Series(y_train), sensitive_features=A_train.sex)\n",
        "    \n",
        "    errors.append(error.gamma(classifier)[0])\n",
        "    disparities.append(disparity.gamma(classifier).max())\n",
        "    \n",
        "all_results = pd.DataFrame( {\"predictor\": predictors, \"error\": errors, \"disparity\": disparities})\n",
        "\n",
        "dominant_models_dict = dict()\n",
        "base_name_format = \"census_gs_model_{0}\"\n",
        "row_id = 0\n",
        "for row in all_results.itertuples():\n",
        "    model_name = base_name_format.format(row_id)\n",
        "    errors_for_lower_or_eq_disparity = all_results[\"error\"][all_results[\"disparity\"]<=row.disparity]\n",
        "    if row.error <= errors_for_lower_or_eq_disparity.min():\n",
        "        dominant_models_dict[model_name] = row.predictor\n",
        "    row_id = row_id + 1"
      ],
      "outputs": [],
      "execution_count": 52,
      "metadata": {
        "gather": {
          "logged": 1624559892519
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can construct predictions for the dominant models (we include the unmitigated predictor as well, for comparison):"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_dominant = {\"census_unmitigated\": unmitigated_predictor.predict(X_test)}\n",
        "models_dominant = {\"census_unmitigated\": unmitigated_predictor}\n",
        "for name, predictor in dominant_models_dict.items():\n",
        "    value = predictor.predict(X_test)\n",
        "    predictions_dominant[name] = value\n",
        "    models_dominant[name] = predictor"
      ],
      "outputs": [],
      "execution_count": 53,
      "metadata": {
        "gather": {
          "logged": 1624559897439
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These predictions may then be viewed in the fairness dashboard. We include the race column from the dataset, as an alternative basis for assessing the models. However, since we have not based our mitigation on it, the variation in the models with respect to race can be large."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "FairlearnDashboard(sensitive_features=A_test[[\"race\"]], \n",
        "                   sensitive_feature_names=['Race'],\n",
        "                   y_true=y_test.tolist(),\n",
        "                   y_pred=predictions_dominant)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/fairlearn/widget/_fairlearn_dashboard.py:47: UserWarning: The FairlearnDashboard will move from Fairlearn to the raiwidgets package after the v0.5.0 release. Instead, Fairlearn will provide some of the existing functionality through matplotlib-based visualizations.\n",
            "  warn(\"The FairlearnDashboard will move from Fairlearn to the \"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "FairlearnWidget(value={'true_y': [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1â¦",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "86f855c3b0764df28e53a86d7649b456"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 54,
          "data": {
            "text/plain": "<fairlearn.widget._fairlearn_dashboard.FairlearnDashboard at 0x7f8fb852df60>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 54,
      "metadata": {
        "gather": {
          "logged": 1624559905184
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When using sex as the sensitive feature and accuracy as the metric, we see a Pareto front forming - the set of predictors which represent optimal tradeoffs between accuracy and disparity in predictions. In the ideal case, we would have a predictor at (1,0) - perfectly accurate and without any unfairness under demographic parity (with respect to the protected attribute \"sex\"). The Pareto front represents the closest we can come to this ideal based on our data and choice of estimator. Note the range of the axes - the disparity axis covers more values than the accuracy, so we can reduce disparity substantially for a small loss in accuracy. Finally, we also see that the unmitigated model is towards the top right of the plot, with high accuracy, but worst disparity.\n",
        "\n",
        "By clicking on individual models on the plot, we can inspect their metrics for disparity and accuracy in greater detail. In a real example, we would then pick the model which represented the best trade-off between accuracy and disparity given the relevant business constraints."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"AzureUpload\"></a>\n",
        "## Uploading a Fairness Dashboard to Azure (one time job)\n",
        "\n",
        "Uploading a fairness dashboard to Azure is a two stage process. The `FairlearnDashboard` invoked in the previous section relies on the underlying Python kernel to compute metrics on demand. This is obviously not available when the fairness dashboard is rendered in AzureML Studio. By default, the dashboard in Azure Machine Learning Studio also requires the models to be registered. The required stages are therefore:\n",
        "1. Register the dominant models\n",
        "1. Precompute all the required metrics\n",
        "1. Upload to Azure\n",
        "\n",
        "Before that, we need to connect to Azure Machine Learning Studio:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Experiment, Model\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "ws.get_details()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:azureml.core.workspace:Found the config file in: /config.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 55,
          "data": {
            "text/plain": "{'id': '/subscriptions/506e86fc-853c-4557-a6e5-ad72114efd2b/resourceGroups/FSI-Demo/providers/Microsoft.MachineLearningServices/workspaces/ml-fsi-prod',\n 'name': 'ml-fsi-prod',\n 'identity': {'principal_id': 'bad11954-41b6-4f4f-9c6a-e3638aac14ce',\n  'tenant_id': 'f94768c8-8714-4abe-8e2d-37a64b18216a',\n  'type': 'SystemAssigned'},\n 'location': 'westus2',\n 'type': 'Microsoft.MachineLearningServices/workspaces',\n 'tags': {},\n 'sku': 'Basic',\n 'workspaceid': '231e4375-50e6-4268-951c-cd3d4f8be8cf',\n 'sdkTelemetryAppInsightsKey': '19f24253-9564-406c-9a1e-a48a21b145aa',\n 'description': '',\n 'friendlyName': 'ml-fsi-prod',\n 'creationTime': '2021-06-15T15:09:40.4825243+00:00',\n 'containerRegistry': '',\n 'keyVault': '/subscriptions/506e86fc-853c-4557-a6e5-ad72114efd2b/resourcegroups/fsi-demo/providers/microsoft.keyvault/vaults/mlfsiprod7591896784',\n 'applicationInsights': '/subscriptions/506e86fc-853c-4557-a6e5-ad72114efd2b/resourcegroups/fsi-demo/providers/microsoft.insights/components/mlfsiprod0383327891',\n 'storageAccount': '/subscriptions/506e86fc-853c-4557-a6e5-ad72114efd2b/resourcegroups/fsi-demo/providers/microsoft.storage/storageaccounts/mlfsiprod0896235210',\n 'hbiWorkspace': False,\n 'allowPublicAccessWhenBehindVnet': False,\n 'provisioningState': 'Succeeded',\n 'imageBuildCompute': '',\n 'discoveryUrl': 'https://westus2.api.azureml.ms/discovery',\n 'notebookInfo': {'fqdn': 'ml-ml-fsi-prod-westus2-231e4375-50e6-4268-951c-cd3d4f8be8cf.notebooks.azure.net',\n  'resource_id': '92dd3b8bf20e4837a247c04913157b0a'}}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 55,
      "metadata": {
        "gather": {
          "logged": 1624560089574
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"RegisterModels\"></a>\n",
        "### Registering Models\n",
        "\n",
        "The fairness dashboard is designed to integrate with registered models, so we need to do this for the models we want in the Studio portal. The assumption is that the names of the models specified in the dashboard dictionary correspond to the `id`s (i.e. `<name>:<version>` pairs) of registered models in the workspace. We register each of the models in the `models_dominant` dictionary into the workspace. For this, we have to save each model to a file, and then register that file:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import os\n",
        "\n",
        "os.makedirs('models', exist_ok=True)\n",
        "def register_model(name, model):\n",
        "    print(\"Registering \", name)\n",
        "    model_path = \"models/{0}.pkl\".format(name)\n",
        "    joblib.dump(value=model, filename=model_path)\n",
        "    registered_model = Model.register(model_path=model_path,\n",
        "                                      model_name=name,\n",
        "                                      workspace=ws)\n",
        "    print(\"Registered \", registered_model.id)\n",
        "    return registered_model.id\n",
        "\n",
        "model_name_id_mapping = dict()\n",
        "for name, model in models_dominant.items():\n",
        "    m_id = register_model(name, model)\n",
        "    model_name_id_mapping[name] = m_id"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Registering  census_unmitigated\n",
            "Registering model census_unmitigated\n",
            "Registered  census_unmitigated:1\n",
            "Registering  census_gs_model_34\n",
            "Registering model census_gs_model_34\n",
            "Registered  census_gs_model_34:1\n",
            "Registering  census_gs_model_35\n",
            "Registering model census_gs_model_35\n",
            "Registered  census_gs_model_35:1\n",
            "Registering  census_gs_model_36\n",
            "Registering model census_gs_model_36\n",
            "Registered  census_gs_model_36:1\n",
            "Registering  census_gs_model_37\n",
            "Registering model census_gs_model_37\n",
            "Registered  census_gs_model_37:1\n",
            "Registering  census_gs_model_38\n",
            "Registering model census_gs_model_38\n",
            "Registered  census_gs_model_38:1\n",
            "Registering  census_gs_model_39\n",
            "Registering model census_gs_model_39\n",
            "Registered  census_gs_model_39:1\n",
            "Registering  census_gs_model_40\n",
            "Registering model census_gs_model_40\n",
            "Registered  census_gs_model_40:1\n",
            "Registering  census_gs_model_41\n",
            "Registering model census_gs_model_41\n",
            "Registered  census_gs_model_41:1\n",
            "Registering  census_gs_model_42\n",
            "Registering model census_gs_model_42\n",
            "Registered  census_gs_model_42:1\n",
            "Registering  census_gs_model_43\n",
            "Registering model census_gs_model_43\n",
            "Registered  census_gs_model_43:1\n",
            "Registering  census_gs_model_44\n",
            "Registering model census_gs_model_44\n",
            "Registered  census_gs_model_44:1\n",
            "Registering  census_gs_model_45\n",
            "Registering model census_gs_model_45\n",
            "Registered  census_gs_model_45:1\n",
            "Registering  census_gs_model_46\n",
            "Registering model census_gs_model_46\n",
            "Registered  census_gs_model_46:1\n",
            "Registering  census_gs_model_47\n",
            "Registering model census_gs_model_47\n",
            "Registered  census_gs_model_47:1\n",
            "Registering  census_gs_model_48\n",
            "Registering model census_gs_model_48\n",
            "Registered  census_gs_model_48:1\n"
          ]
        }
      ],
      "execution_count": 56,
      "metadata": {
        "gather": {
          "logged": 1624560121998
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, produce new predictions dictionaries, with the updated names:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_dominant_ids = dict()\n",
        "for name, y_pred in predictions_dominant.items():\n",
        "    predictions_dominant_ids[model_name_id_mapping[name]] = y_pred"
      ],
      "outputs": [],
      "execution_count": 57,
      "metadata": {
        "gather": {
          "logged": 1624560156341
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"PrecomputeMetrics\"></a>\n",
        "### Precomputing Metrics\n",
        "\n",
        "We create a _dashboard dictionary_ using Fairlearn's `metrics` package. The `_create_group_metric_set` method has arguments similar to the Dashboard constructor, except that the sensitive features are passed as a dictionary (to ensure that names are available), and we must specify the type of prediction. Note that we use the `predictions_dominant_ids` dictionary we just created:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "sf = {'race': A_test.race }\n",
        "\n",
        "from fairlearn.metrics._group_metric_set import _create_group_metric_set\n",
        "\n",
        "\n",
        "dash_dict = _create_group_metric_set(y_true=y_test,\n",
        "                                     predictions=predictions_dominant_ids,\n",
        "                                     sensitive_features=sf,\n",
        "                                     prediction_type='binary_classification')"
      ],
      "outputs": [],
      "execution_count": 58,
      "metadata": {
        "gather": {
          "logged": 1624560194073
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"DashboardUpload\"></a>\n",
        "### Uploading the Dashboard\n",
        "\n",
        "Now, we import our `contrib` package which contains the routine to perform the upload:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.contrib.fairness import upload_dashboard_dictionary, download_dashboard_by_upload_id"
      ],
      "outputs": [],
      "execution_count": 59,
      "metadata": {
        "gather": {
          "logged": 1624560194343
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can create an Experiment, then a Run, and upload our dashboard to it:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "exp = Experiment(ws, \"Fairlearn_GridSearch_Experiment_for_Race_v2\")\n",
        "print(exp)\n",
        "\n",
        "run = exp.start_logging()\n",
        "try:\n",
        "    dashboard_title = \"Dominant Models from GridSearch\"\n",
        "    upload_id = upload_dashboard_dictionary(run,\n",
        "                                            dash_dict,\n",
        "                                            dashboard_name=dashboard_title)\n",
        "    print(\"\\nUploaded to id: {0}\\n\".format(upload_id))\n",
        "\n",
        "    downloaded_dict = download_dashboard_by_upload_id(run, upload_id)\n",
        "finally:\n",
        "    run.complete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment(Name: Fairlearn_GridSearch_Experiment_for_Race_v2,\n",
            "Workspace: ml-fsi-prod)\n",
            "\n",
            "Uploaded to id: 24c11d02-a056-4ddc-ab8c-86e76c697d0c\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_dashboard_validation.py:Starting validation of dashboard dictionary\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_dashboard_validation.py:Validation of dashboard dictionary successful\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_azureml_validation.py:Validating model ids exist\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_azureml_validation.py:Checking census_gs_model_34:1\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_azureml_validation.py:Checking census_gs_model_35:1\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_azureml_validation.py:Checking census_gs_model_36:1\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_azureml_validation.py:Checking census_gs_model_37:1\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_azureml_validation.py:Checking census_gs_model_38:1\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_azureml_validation.py:Checking census_gs_model_39:1\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_azureml_validation.py:Checking census_gs_model_40:1\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_azureml_validation.py:Checking census_gs_model_41:1\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_azureml_validation.py:Checking census_gs_model_42:1\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_azureml_validation.py:Checking census_gs_model_43:1\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_azureml_validation.py:Checking census_gs_model_44:1\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_azureml_validation.py:Checking census_gs_model_45:1\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_azureml_validation.py:Checking census_gs_model_46:1\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_azureml_validation.py:Checking census_gs_model_47:1\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_azureml_validation.py:Checking census_gs_model_48:1\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_azureml_validation.py:Checking census_unmitigated:1\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_azureml_validation.py:Validation of model ids complete\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Uploading y_true\n",
            "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_true/05ffe60e-cd69-43a5-94a7-9068564878c5.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded y_true to prefix azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_true/05ffe60e-cd69-43a5-94a7-9068564878c5.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Found 16 predictions\n",
            "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/b008d84b-2fb6-40ee-83fe-4601b4e76758.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded prediction to prefix azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/b008d84b-2fb6-40ee-83fe-4601b4e76758.json\n",
            "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/755fa05f-967f-4c70-95db-2de7e89e6c8e.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded prediction to prefix azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/755fa05f-967f-4c70-95db-2de7e89e6c8e.json\n",
            "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/fac9d6d2-ade9-4d94-949c-37caaad1689a.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded prediction to prefix azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/fac9d6d2-ade9-4d94-949c-37caaad1689a.json\n",
            "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/4dc62315-6d64-4682-ab7a-6d4cff193f2e.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded prediction to prefix azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/4dc62315-6d64-4682-ab7a-6d4cff193f2e.json\n",
            "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/95397874-951b-4db9-8b6a-51624f58730a.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded prediction to prefix azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/95397874-951b-4db9-8b6a-51624f58730a.json\n",
            "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/db198da7-7d5d-4d06-952c-62bcbce4972a.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded prediction to prefix azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/db198da7-7d5d-4d06-952c-62bcbce4972a.json\n",
            "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/f033ecea-65a1-4972-880d-85a85b0f19cb.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded prediction to prefix azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/f033ecea-65a1-4972-880d-85a85b0f19cb.json\n",
            "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/84589068-169f-4653-a1c1-948bdfbfa1ef.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded prediction to prefix azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/84589068-169f-4653-a1c1-948bdfbfa1ef.json\n",
            "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/41b91f7e-a49e-4435-a71e-ee2cd33ddaab.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded prediction to prefix azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/41b91f7e-a49e-4435-a71e-ee2cd33ddaab.json\n",
            "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/11893a1c-4860-4820-96a9-532d19c667c5.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded prediction to prefix azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/11893a1c-4860-4820-96a9-532d19c667c5.json\n",
            "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/06ec5245-d78f-4d76-aad7-a4601ea5f4ad.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded prediction to prefix azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/06ec5245-d78f-4d76-aad7-a4601ea5f4ad.json\n",
            "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/de596561-6edf-4be3-940c-b9491fa03749.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded prediction to prefix azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/de596561-6edf-4be3-940c-b9491fa03749.json\n",
            "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/a2c62f18-c2c7-4022-8967-7cfdba70462b.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded prediction to prefix azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/a2c62f18-c2c7-4022-8967-7cfdba70462b.json\n",
            "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/d1b0880c-af6d-401a-9d3a-a122d786ef8a.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded prediction to prefix azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/d1b0880c-af6d-401a-9d3a-a122d786ef8a.json\n",
            "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/88510d6d-cad7-4a10-a629-2a63beb8478e.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded prediction to prefix azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/88510d6d-cad7-4a10-a629-2a63beb8478e.json\n",
            "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/f5dda78f-bb07-4afa-90a7-58c81cac3bca.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded prediction to prefix azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/f5dda78f-bb07-4afa-90a7-58c81cac3bca.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded 16 predictions\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Found {0} sensitive features\n",
            "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/sensitive_features_column/e63d5bb3-8bff-4b09-9d96-09340a8bf44c.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded sensitive feature column to prefix azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/sensitive_features_column/e63d5bb3-8bff-4b09-9d96-09340a8bf44c.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded 1 sensitive features\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Uploading metrics\n",
            "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/metrics_set/2ab2e8ff-6241-4c47-96f3-ae25e115b763.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded metrics data for prediction 0 and sensitive_feature 0\n",
            "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/metrics_set/1cab5b35-ee66-4c8a-be29-285d61f889e1.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded metrics data for prediction 1 and sensitive_feature 0\n",
            "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/metrics_set/e4bd5151-edbd-4acd-953a-607f3ab6f414.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded metrics data for prediction 2 and sensitive_feature 0\n",
            "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/metrics_set/9e584629-2aa2-4c0e-92f1-494b802bceaa.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded metrics data for prediction 3 and sensitive_feature 0\n",
            "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/metrics_set/f461c1ba-30ed-48b5-8d58-c2b3413cebde.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded metrics data for prediction 4 and sensitive_feature 0\n",
            "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/metrics_set/d5207426-3546-48a6-81b2-de441a06c5b9.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded metrics data for prediction 5 and sensitive_feature 0\n",
            "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/metrics_set/17161448-4041-484e-a375-18b2005c3ae3.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded metrics data for prediction 6 and sensitive_feature 0\n",
            "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/metrics_set/0b6d42b5-42fa-4e36-9bcb-641b57663dca.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded metrics data for prediction 7 and sensitive_feature 0\n",
            "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/metrics_set/71973c9e-053c-45be-bda0-0fa2869fb1b5.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded metrics data for prediction 8 and sensitive_feature 0\n",
            "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/metrics_set/4bcf632a-e772-4381-af0a-338995e99746.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded metrics data for prediction 9 and sensitive_feature 0\n",
            "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/metrics_set/49ca4fde-0b85-4165-b843-e3a158df19d6.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded metrics data for prediction 10 and sensitive_feature 0\n",
            "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/metrics_set/63224bf3-bc6c-43a9-95f7-fafb4bff4b45.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded metrics data for prediction 11 and sensitive_feature 0\n",
            "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/metrics_set/39928534-668e-4b43-a804-d81b8ce8d80d.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded metrics data for prediction 12 and sensitive_feature 0\n",
            "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/metrics_set/276573c9-c5df-4262-a362-33656bcc5a84.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded metrics data for prediction 13 and sensitive_feature 0\n",
            "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/metrics_set/d9a97c1b-687b-4554-97fc-ec7de0ef33f4.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded metrics data for prediction 14 and sensitive_feature 0\n",
            "INFO:azureml.FairnessArtifactClient:Uploading to azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/metrics_set/eeb43e5b-0625-4a33-b4fa-cfe1ef8c66bd.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_specific_uploaders.py:Uploaded metrics data for prediction 15 and sensitive_feature 0\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Creating CUF Assets\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Asset uploaded with id 92a1e73573894308987eb2c4d287ba6a\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Asset uploaded with id 9b014885c09a429093453a1775fff131\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Asset uploaded with id cac1af73280e4c65a855a49efbdb6f68\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Asset uploaded with id d8f859b8325d400e88b36d3a17310171\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Asset uploaded with id 265ed55fe8d8413c9211e9c402a210b9\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Asset uploaded with id 8863d59b91834be4aa3a35823c1e77ca\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Asset uploaded with id 093658147e9c4a2ea861902856b8d51d\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Asset uploaded with id 22b4b5fa7cd64ee593decd7c88adfdea\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Asset uploaded with id ad653285951640fbbe1296adee244f18\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Asset uploaded with id 9c54217d49e84af1a469b6c02614c839\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Asset uploaded with id 7d2cbc7a320b4863871437e5067d33c1\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Asset uploaded with id 6789b9374a0e4851b6ded3db9e623219\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Asset uploaded with id 914d3e0291904b889ef2024dde1d973e\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Asset uploaded with id 33caa85a01934deda55272a31fd1d461\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Asset uploaded with id f6c01b8b71574e7a9b867ba743f1c018\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Asset uploaded with id 6226411aae044a7d905f0d29d7099a00\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Fetching asset list\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Populating y_true\n",
            "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_true/05ffe60e-cd69-43a5-94a7-9068564878c5.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Populating y_pred\n",
            "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/b008d84b-2fb6-40ee-83fe-4601b4e76758.json\n",
            "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/755fa05f-967f-4c70-95db-2de7e89e6c8e.json\n",
            "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/fac9d6d2-ade9-4d94-949c-37caaad1689a.json\n",
            "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/4dc62315-6d64-4682-ab7a-6d4cff193f2e.json\n",
            "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/95397874-951b-4db9-8b6a-51624f58730a.json\n",
            "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/db198da7-7d5d-4d06-952c-62bcbce4972a.json\n",
            "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/f033ecea-65a1-4972-880d-85a85b0f19cb.json\n",
            "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/84589068-169f-4653-a1c1-948bdfbfa1ef.json\n",
            "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/41b91f7e-a49e-4435-a71e-ee2cd33ddaab.json\n",
            "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/11893a1c-4860-4820-96a9-532d19c667c5.json\n",
            "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/06ec5245-d78f-4d76-aad7-a4601ea5f4ad.json\n",
            "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/de596561-6edf-4be3-940c-b9491fa03749.json\n",
            "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/a2c62f18-c2c7-4022-8967-7cfdba70462b.json\n",
            "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/d1b0880c-af6d-401a-9d3a-a122d786ef8a.json\n",
            "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/88510d6d-cad7-4a10-a629-2a63beb8478e.json\n",
            "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/y_pred/f5dda78f-bb07-4afa-90a7-58c81cac3bca.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Populating sensitive features\n",
            "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/sensitive_features_column/e63d5bb3-8bff-4b09-9d96-09340a8bf44c.json\n",
            "INFO:/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/fairness/_fairness_client.py:Populating metrics\n",
            "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/metrics_set/2ab2e8ff-6241-4c47-96f3-ae25e115b763.json\n",
            "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/metrics_set/1cab5b35-ee66-4c8a-be29-285d61f889e1.json\n",
            "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/metrics_set/e4bd5151-edbd-4acd-953a-607f3ab6f414.json\n",
            "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/metrics_set/9e584629-2aa2-4c0e-92f1-494b802bceaa.json\n",
            "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/metrics_set/f461c1ba-30ed-48b5-8d58-c2b3413cebde.json\n",
            "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/metrics_set/d5207426-3546-48a6-81b2-de441a06c5b9.json\n",
            "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/metrics_set/17161448-4041-484e-a375-18b2005c3ae3.json\n",
            "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/metrics_set/0b6d42b5-42fa-4e36-9bcb-641b57663dca.json\n",
            "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/metrics_set/71973c9e-053c-45be-bda0-0fa2869fb1b5.json\n",
            "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/metrics_set/4bcf632a-e772-4381-af0a-338995e99746.json\n",
            "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/metrics_set/49ca4fde-0b85-4165-b843-e3a158df19d6.json\n",
            "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/metrics_set/63224bf3-bc6c-43a9-95f7-fafb4bff4b45.json\n",
            "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/metrics_set/39928534-668e-4b43-a804-d81b8ce8d80d.json\n",
            "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/metrics_set/276573c9-c5df-4262-a362-33656bcc5a84.json\n",
            "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/metrics_set/d9a97c1b-687b-4554-97fc-ec7de0ef33f4.json\n",
            "INFO:azureml.FairnessArtifactClient:Downloading from azureml.fairness/dashboard.metrics/24c11d02-a056-4ddc-ab8c-86e76c697d0c/metrics_set/eeb43e5b-0625-4a33-b4fa-cfe1ef8c66bd.json\n"
          ]
        }
      ],
      "execution_count": 60,
      "metadata": {
        "gather": {
          "logged": 1624560227330
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dashboard can be viewed in the Run Details page.\n",
        "\n",
        "Finally, we can verify that the dashboard dictionary which we downloaded matches our upload:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(dash_dict == downloaded_dict)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "execution_count": 31,
      "metadata": {
        "gather": {
          "logged": 1623350485529
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"Conclusion\"></a>\n",
        "## Conclusion\n",
        "\n",
        "In this notebook we have demonstrated how to use the `GridSearch` algorithm from Fairlearn to generate a collection of models, and then present them in the fairness dashboard in Azure Machine Learning Studio. Please remember that this notebook has not attempted to discuss the many considerations which should be part of any approach to unfairness mitigation. The [Fairlearn website](http://fairlearn.org/) provides that discussion"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "authors": [
      {
        "name": "riedgar"
      }
    ],
    "kernel_info": {
      "name": "python3-azureml"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}