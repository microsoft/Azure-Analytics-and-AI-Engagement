{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Azure Machine Learning datasets for Customer Churn prediction\n",
        "\n",
        "Azure Machine Learning datasets can be extremely useful for your local or remote experiments. In this notebook, we will do the following things.\n",
        "\n",
        "1. Configure workspace using credentials for Azure subscription\n",
        "2. Download the dataset from ADLS Gen2\n",
        "3. Upload the featured dataset into the default datastore in Azure\n",
        "4. Register the featured dataset into Azure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## *****For Demonstration purpose only, Please customize as per your enterprise security needs and compliances***** \n"
		"Disclaimer: By accessing this code, you acknowledge the code is made available for presentation and demonstration purposes only and that the code: (1) is not subject to SOC 1 and SOC 2 compliance audits; (2) is not designed or intended to be a substitute for the professional advice, diagnosis, treatment, or judgment of a certified financial services professional; (3) is not designed, intended or made available as a medical device; and (4) is not designed or intended to be a substitute for professional medical advice, diagnosis, treatment or judgement. Do not use this code to replace, substitute, or provide professional financial advice or judgment, or to replace, substitute or provide medical advice, diagnosis, treatment or judgement. You are solely responsible for ensuring the regulatory, legal, and/or contractual compliance of any use of the code, including obtaining any authorizations or consents, and any solution you choose to build that incorporates this code in whole or in part. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configure workspace using credentials for Azure subscription\n",
        "\n",
        "As part of the setup you have already created a Workspace. To run AutoML, you also need to create an Experiment. An Experiment corresponds to a prediction problem you are trying to solve, while a Run corresponds to a specific approach to the problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "FinanceSpk",
              "session_id": 57,
              "statement_id": 1,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-07-14T20:38:34.0709207Z",
              "session_start_time": "2021-07-14T20:38:34.0982494Z",
              "execution_start_time": "2021-07-14T20:40:36.6423482Z",
              "execution_finish_time": "2021-07-14T20:40:51.0965882Z"
            },
            "text/plain": "StatementMeta(FinanceSpk, 57, 1, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Workspace configuration succeeded. Skip the workspace creation steps below"
        }
      ],
      "metadata": {},
      "source": [
        "# Install the required package\n",
        "# import pip \n",
        "# pip.main(['install','azure-storage-blob==2.1.0'])\n",
        "# !pip install azure-storage-blob==2.1.0\n",
        "\n",
        "from azureml.core import Workspace\n",
        "\n",
        "subscription_id='#SUBSCRIPTION_ID#'\n",
        "resource_group='#RESOURCE_GROUP_NAME#'\n",
        "workspace_name='#ML_WORKSPACE_NAME#'\n",
        "\n",
        "try:\n",
        "    workspace = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\n",
        "    # write the details of the workspace to a configuration file to the notebook library\n",
        "    workspace.write_config()\n",
        "    print(\"Workspace configuration succeeded. Skip the workspace creation steps below\")\n",
        "except:\n",
        "    print(\"Workspace not accessible. Change your parameters or create a new workspace below\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download the  dataset from ADLS Gen2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "FinanceSpk",
              "session_id": 57,
              "statement_id": 2,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-07-14T20:38:34.0722687Z",
              "session_start_time": null,
              "execution_start_time": "2021-07-14T20:40:51.1893145Z",
              "execution_finish_time": "2021-07-14T20:40:55.3198797Z"
            },
            "text/plain": "StatementMeta(FinanceSpk, 57, 2, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": ""
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "from azure.storage.blob import ContainerClient, BlobClient\r\n",
        "import pandas as pd\r\n",
        "from io import BytesIO\r\n",
        "\r\n",
        "CONNECTIONSTRING = 'DefaultEndpointsProtocol=https;AccountName=stfsiprod;AccountKey=WVrgvqHHELb6+XKiurG3qiPyNf48vF2L5LGpQPtR5n2J6VHPdSex6VN1H7a+73PNFRomme11g/1mVdl32kBiLA==;EndpointSuffix=core.windows.net'\r\n",
        "CONTAINER_NAME = 'retail-banking-customer-churn'\r\n",
        "\r\n",
        "BLOBNAME = 'retail_banking_customer_churn_for_model.csv'\r\n",
        "blob = BlobClient.from_connection_string(conn_str=CONNECTIONSTRING, container_name=CONTAINER_NAME, blob_name=BLOBNAME)\r\n",
        "blob_data = blob.download_blob()\r\n",
        "BytesIO(blob_data.content_as_bytes())\r\n",
        "# uploading the csv to the ADLSGen2 storage container\r\n",
        "data = pd.read_csv(BytesIO(blob_data.content_as_bytes()))\r\n",
        "data.to_csv(BLOBNAME,header=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "FinanceSpk",
              "session_id": 57,
              "statement_id": 3,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-07-14T20:41:24.1516802Z",
              "session_start_time": null,
              "execution_start_time": "2021-07-14T20:41:24.2493775Z",
              "execution_finish_time": "2021-07-14T20:41:26.2959109Z"
            },
            "text/plain": "StatementMeta(FinanceSpk, 57, 3, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "   age  marital  housing  ...  job_student  job_technician  job_unemployed\n0   56        1        1  ...            0               0               0\n1   57        1        1  ...            0               0               0\n2   37        1        2  ...            0               0               0\n3   40        1        1  ...            0               0               0\n4   56        1        1  ...            0               0               0\n\n[5 rows x 32 columns]"
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Upload the featured dataset into the default datastore in Azure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "FinanceSpk",
              "session_id": 57,
              "statement_id": 5,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-07-14T20:42:10.4306911Z",
              "session_start_time": null,
              "execution_start_time": "2021-07-14T20:42:10.5211365Z",
              "execution_finish_time": "2021-07-14T20:42:20.8209646Z"
            },
            "text/plain": "StatementMeta(FinanceSpk, 57, 5, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Uploading an estimated of 1 files\nUploading ./data/retail_banking_customer_churn_for_model.csv\nUploaded ./data/retail_banking_customer_churn_for_model.csv, 1 files out of an estimated total of 1\nUploaded 1 files"
        }
      ],
      "metadata": {},
      "source": [
        "from shutil import copyfile\n",
        "from sklearn import datasets\n",
        "from azureml.core.dataset import Dataset\n",
        "from scipy import sparse\n",
        "import os \n",
        " \n",
        "\n",
        "# Create a project_folder if it doesn't exist\n",
        "if not os.path.isdir('data'):\n",
        " os.mkdir('data')\n",
        " \n",
        "copyfile(\"retail_banking_customer_churn_for_model.csv\", \"data/retail_banking_customer_churn_for_model.csv\") \n",
        "ds = workspace.get_default_datastore()\n",
        "ds.upload(src_dir='./data', target_path='retail_banking', overwrite=True, show_progress=True)\n",
        " \n",
        "final_df = Dataset.Tabular.from_delimited_files(path=ds.path('retail_banking/retail_banking_customer_churn_for_model.csv'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Register the featured dataset into Azure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "FinanceSpk",
              "session_id": 57,
              "statement_id": 7,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-07-14T20:43:00.4533179Z",
              "session_start_time": null,
              "execution_start_time": "2021-07-14T20:43:00.5500585Z",
              "execution_finish_time": "2021-07-14T20:43:02.6076616Z"
            },
            "text/plain": "StatementMeta(FinanceSpk, 57, 7, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": ""
        }
      ],
      "metadata": {},
      "source": [
        "# train_data_registered = Dataset.get_by_name(amlworkspace,\"train_data\",version='latest')\n",
        "#train_data_registered.unregister_all_versions()\n",
        "\n",
        "train_data_registered = final_df.register(workspace=workspace,\n",
        "                                 name='customer_churn',\n",
        "                                 description='Synapse Retail Banking Customer Churn Dataset - Original',\n",
        "                                 tags= {'type': 'Banking', 'date':'2020'},\n",
        "                                 create_new_version=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "save_output": true,
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  }
}