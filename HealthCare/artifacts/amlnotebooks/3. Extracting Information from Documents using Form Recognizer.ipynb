{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Extraction from Documents in Healthcare - Automatic Form Recognition \n",
    "<h3><span style=\"color: #117d30;\"> Using Azure Form Recognizer</span></h3>"
   ]
  },
  {
      "cell_type": "markdown",
      "source": [
        "$*****$ For Demonstration purpose only, Please customize as per your enterprise security needs and compliances.License agreement: https://github.com/microsoft/Azure-Analytics-and-AI-Engagement/blob/main/HealthCare/License.md $*****$ "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
	{
      "cell_type": "markdown",
      "source": [
        "## Legal Notices \r\n",
        "\r\n",
        "This presentation, demonstration, and demonstration model are for informational purposes only. Microsoft makes no warranties, express or implied, in this presentation demonstration, and demonstration model. Nothing in this presentation, demonstration, or demonstration model modifies any of the terms and conditions of Microsoft’s written and signed agreements. This is not an offer and applicable terms and the information provided is subject to revision and may be changed at any time by Microsoft.\r\n",
        "\r\n",
        "This presentation, demonstration, and/or demonstration model do not give you or your organization any license to any patents, trademarks, copyrights, or other intellectual property covering the subject matter in this presentation, demonstration, and demonstration model.\r\n",
        "\r\n",
        "The information contained in this presentation, demonstration and demonstration model represent the current view of Microsoft on the issues discussed as of the date of presentation and/or demonstration, and the duration of your access to the demonstration model. Because Microsoft must respond to changing market conditions, it should not be interpreted to be a commitment on the part of Microsoft, and Microsoft cannot guarantee the accuracy of any information presented after the date of presentation and/or demonstration and for the duration of your access to the demonstration model.\r\n",
        "\r\n",
        "No Microsoft technology, nor any of its component technologies, including the demonstration model, is intended or made available: (1) as a medical device; (2) for the diagnosis of disease or other conditions, or in the cure, mitigation, treatment or prevention of a disease or other conditions; or (3) as a substitute for the professional clinical advice, opinion, or judgment of a treating healthcare professional. Partners or customers are responsible for ensuring the regulatory compliance of any solution they build using Microsoft technologies.\r\n",
        "\r\n",
        "© 2020 Microsoft Corporation. All rights reserved"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://pocaccelerator.blob.core.windows.net/webappassets/patient_form.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure Form Recognizer\n",
    "\n",
    "Azure Form Recognizer is a cognitive service that uses machine learning technology to identify and extract key-value pairs and table data from form documents. It then outputs structured data that includes the relationships in the original file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario Overview\n",
    "\n",
    "\n",
    "Azure Form Recognizer is a cognitive service that uses machine learning technology to identify and extract key-value pairs and table data from form documents. It then outputs structured data that includes the relationships in the original file.\n",
    "\n",
    "Patient Intake Form Dataset: Raw unstructured data is fed into the pipeline in the form of electronically generated PDFs. These reports contain information about injuries that occurred at 5 different hospital locations. This data provides information on patient intake forms, including the allergies, conditions, symptoms, and the other information about patients.\n",
    "\n",
    "### Notebook Organization\n",
    "\n",
    "- Fetch the patient intake  PDF files from a container under an azure storage account.\n",
    "- Convert the PDF files to JSON by querying the azure trained form recognizer model using the REST API.\n",
    "- Preprocess the JSON files to extract only relevant information.\n",
    "- Push the JSON files to a container under an azure storage account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "gather": {
     "logged": 1606151339086
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import requests\n",
    "import os\n",
    "from azure.storage.blob import ContainerClient\n",
    "import pprint\n",
    "import json\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import shutil\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/batch/tasks/shared/LS_root/mounts/clusters/vmhealthcare001/code/Users/demo-healthcare-user/notebooks'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating local directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "gather": {
     "logged": 1606151339146
    }
   },
   "outputs": [],
   "source": [
    "# Create local directories if they don't exist\n",
    "\n",
    "# *input_forms* contains all the pdf files\n",
    "input_path = os.getcwd()+\"/input_forms\"\n",
    "output_path = os.getcwd()+\"/output_json\"\n",
    "\n",
    "if (not os.path.isdir(input_path)):\n",
    "    os.makedirs(input_path)\n",
    "\n",
    "# *output_json* will contain all the converted json files\n",
    "if (not os.path.isdir(output_path)):\n",
    "    os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establishing connection to Azure blob storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GlobalVariables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "gather": {
     "logged": 1606151339583
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "CONNECTION_STRING = GlobalVariables.STORAGE_ACCOUNT_CONNECTION_STRING\n",
    "CONTAINER_NAME = \"formuploadv2\"\n",
    "\n",
    "# creating blob service object and list blobs inside input_folder\n",
    "\n",
    "container_client = ContainerClient.from_connection_string(conn_str=CONNECTION_STRING, container_name=CONTAINER_NAME)\n",
    "blobs_list = container_client.list_blobs()\n",
    "\n",
    "# initializing several lists that will be used in the following cells\n",
    "blob_client_list=[]\n",
    "blob_file_list = []\n",
    "\n",
    "# getting the blob clients and appending them to a list\n",
    "for c in blobs_list:\n",
    "    blob_client = container_client.get_blob_client(c)\n",
    "    blob_file_list.append(c.name)\n",
    "    blob_client_list.append(blob_client)\n",
    "\n",
    "for filename, blob_client in zip(blob_file_list, blob_client_list):\n",
    "    fname = os.path.join(input_path,filename)\n",
    "    with open(fname, \"wb\") as blob_file:\n",
    "        download_stream = blob_client.download_blob()\n",
    "        download_stream.readinto(blob_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Azure Form Recognizer service on forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp <Response [202]>\n",
      "POST analyze succeeded:\n",
      "{'Content-Length': '0', 'Operation-Location': 'https://cog-formrecognitionv2.cognitiveservices.azure.com/formrecognizer/v2.1-preview.2/custom/models/e46eb4c0-0e9a-4759-b980-28d5cf477236/analyzeresults/f3710d50-61b8-4f75-805f-fc6387d45d21', 'x-envoy-upstream-service-time': '159', 'apim-request-id': 'b34dae70-1b24-4b0b-8191-3cc953015492', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'Date': 'Fri, 04 Dec 2020 18:03:18 GMT'}\n",
      "Analysis succeeded:\n",
      "Patient_Intake_Form10 \n",
      "\n",
      "resp <Response [202]>\n",
      "POST analyze succeeded:\n",
      "{'Content-Length': '0', 'Operation-Location': 'https://cog-formrecognitionv2.cognitiveservices.azure.com/formrecognizer/v2.1-preview.2/custom/models/e46eb4c0-0e9a-4759-b980-28d5cf477236/analyzeresults/1cead4e6-fc1c-41ff-9b15-d05d4dbff026', 'x-envoy-upstream-service-time': '53', 'apim-request-id': '48450a07-f6b3-4226-9ca0-ce49110f2ad1', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'Date': 'Fri, 04 Dec 2020 18:03:34 GMT'}\n",
      "Analysis succeeded:\n",
      "Patient_Intake_Form11 \n",
      "\n",
      "resp <Response [202]>\n",
      "POST analyze succeeded:\n",
      "{'Content-Length': '0', 'Operation-Location': 'https://cog-formrecognitionv2.cognitiveservices.azure.com/formrecognizer/v2.1-preview.2/custom/models/e46eb4c0-0e9a-4759-b980-28d5cf477236/analyzeresults/a6c7a5a1-6368-4891-9a36-5a669858cdf2', 'x-envoy-upstream-service-time': '71', 'apim-request-id': 'c20976f4-92f7-474b-a310-405bf4e1f3a4', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'Date': 'Fri, 04 Dec 2020 18:03:50 GMT'}\n",
      "Analysis succeeded:\n",
      "Patient_Intake_Form9 \n",
      "\n",
      "CPU times: user 247 ms, sys: 33.9 ms, total: 281 ms\n",
      "Wall time: 48.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "files = [f for f in listdir(os.getcwd()+\"/input_forms\") if isfile(join(os.getcwd()+\"/input_forms\", f))]\n",
    "\n",
    "# Endpoint parameters for querying the customer trained form-recognizer model to return the processed JSON\n",
    "# Processes PDF files one by one and return JSON files\n",
    "endpoint = GlobalVariables.FORM_RECOGNIZER_ENDPOINT\n",
    "apim_key = GlobalVariables.FORM_RECOGNIZER_API_KEY\n",
    "model_id = GlobalVariables.FORM_RECOGNIZER_MODEL_ID\n",
    "post_url = endpoint + \"/formrecognizer/v2.1-preview.2/custom/models/%s/analyze\" % model_id\n",
    "params = {\"includeTextDetails\": True}\n",
    "headers = {'Content-Type': 'application/pdf', 'Ocp-Apim-Subscription-Key': apim_key}\n",
    "\n",
    "local_path = input_path\n",
    "\n",
    "\n",
    "for file in files:\n",
    "    with open(os.path.join(local_path,file), \"rb\") as f:\n",
    "        data_bytes = f.read()\n",
    "        \n",
    "    try:\n",
    "        resp = requests.post(url = post_url, data = data_bytes, headers = headers, params = params)\n",
    "        print('resp',resp)\n",
    "        if resp.status_code != 202:\n",
    "            print(\"POST analyze failed:\\n%s\" % json.dumps(resp.json()))\n",
    "            quit()\n",
    "        print(\"POST analyze succeeded:\\n%s\" % resp.headers)\n",
    "        get_url = resp.headers[\"operation-location\"]\n",
    "    except Exception as e:\n",
    "        print(\"POST analyze failed:\\n%s\" % str(e))\n",
    "        quit()\n",
    "     \n",
    "    n_tries = 50\n",
    "    n_try = 0\n",
    "    wait_sec = 5\n",
    "    max_wait_sec = 60\n",
    "    while n_try < n_tries:\n",
    "        try:\n",
    "            resp = requests.get(url = get_url, headers = {\"Ocp-Apim-Subscription-Key\": apim_key})\n",
    "            resp_json = resp.json()\n",
    "            if resp.status_code != 200:\n",
    "                print(\"GET analyze results failed:\\n%s\" % json.dumps(resp_json))\n",
    "                quit()\n",
    "            status = resp_json[\"status\"]\n",
    "#             print(status)\n",
    "            output = json.dumps(resp_json)\n",
    "            \n",
    "            \n",
    "            if status == \"succeeded\":\n",
    "                output_dict = json.loads(output)\n",
    "                        \n",
    "                print(\"Analysis succeeded:\\n%s \\n\" % file[:-4])\n",
    "                \n",
    "                form_inputs = resp_json['analyzeResult']['documentResults'][0]['fields']\n",
    "                tags = list(form_inputs.keys())\n",
    "\n",
    "                temp = {}\n",
    "                types= ''\n",
    "                \n",
    "                for tag in tags: \n",
    "                    if form_inputs[tag] != None:\n",
    "                        types = form_inputs[tag]['type']\n",
    "                        data = form_inputs[tag]['text']\n",
    "                        if types == 'selectionMark':\n",
    "                            if data == 'selected':\n",
    "                                field = tag.split('_')\n",
    "                                field_name = field[0]\n",
    "                                option_chosen = field[-1]\n",
    "                                \n",
    "                                if field_name in temp: \n",
    "                                    temp_data = temp[field_name]\n",
    "                                    temp_data.append(option_chosen)\n",
    "                                    temp[field_name] = temp_data\n",
    "                                else:\n",
    "                                \n",
    "                                    temp[field_name] = [option_chosen]\n",
    "                            else: \n",
    "                                continue\n",
    "                        else: \n",
    "                            temp[tag] = data\n",
    "                            \n",
    "                \n",
    "                    with open(os.path.join(output_path,file[:-4]+\".json\"), 'w') as outfile:\n",
    "                        json.dump(temp, outfile)\n",
    "                break\n",
    "            if status == \"failed\":\n",
    "                print(\"Analysis failed:\\n%s\" % json.dumps(resp_json))\n",
    "                quit()\n",
    "            # Analysis still running. Wait and retry.\n",
    "            time.sleep(wait_sec)\n",
    "            n_try += 1\n",
    "            wait_sec = min(2*wait_sec, max_wait_sec)     \n",
    "        except Exception as e:\n",
    "            msg = \"GET analyze results failed:\\n%s\" % str(e)\n",
    "            print(msg)\n",
    "            quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## Connection parameters for uploading to Azure blob storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1605896373786
    }
   },
   "outputs": [],
   "source": [
    "# Connection paramters for uploading JSON files to blob storage\n",
    "CONNECTION_STRING = GlobalVariables.STORAGE_ACCOUNT_CONNECTION_STRING\n",
    "CONTAINER_NAME = \"formjson\"\n",
    "\n",
    "container_client_upload = ContainerClient.from_connection_string(conn_str=CONNECTION_STRING, container_name=CONTAINER_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading JSON files to Azure blob storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1605896374095
    }
   },
   "outputs": [],
   "source": [
    "# Upload JSON files from local folder *output_json* to the container *formrecogoutput*\n",
    "\n",
    "for pth, dirs, files in os.walk(output_path):\n",
    "    for filename in files:\n",
    "        with open (os.path.join(output_path,filename),'rb') as json_file: \n",
    "            blob_client =  container_client_upload.upload_blob(name=filename, data=json_file,overwrite=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
